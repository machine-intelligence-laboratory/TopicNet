<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.6.3" />
<title>topicnet.cooking_machine.experiment API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase;cursor:pointer}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>topicnet.cooking_machine.experiment</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>Source code</summary>
<pre><code class="python">import os
import re
import json
import warnings

from .model_tracking import Tree, START
from typing import List

from .pretty_output import give_strings_description, get_html
from .routine import transform_topic_model_description_to_jsonable
from .routine import (
    parse_query_string,
    choose_best_models,
    compute_special_queries,
    choose_value_for_models_num_and_check
)
from .routine import is_saveable_model

from .models import BaseModel
from .models.base_model import MODEL_NAME_LENGTH

W_EMPTY_SPECIAL_1 = &#39;Unable to calculate special functions in query\n&#39;
W_EMPTY_SPECIAL_2 = &#39;Process failed with following: {}&#39;
EMPTY_ERRORS = [
    &#39;mean requires at least one data point&#39;,
    &#39;no median for empty data&#39;,
    &#39;min() arg is an empty sequence&#39;,
    &#39;max() arg is an empty sequence&#39;,
]


def _run_from_notebook():
    try:
        shell = get_ipython().__class__.__name__  # noqa: F821
        return shell == &#39;ZMQInteractiveShell&#39;
    except:  # noqa: E722
        return False


class Experiment(object):
    &#34;&#34;&#34;
    Contains experiment, its description and descriptions of all models in the experiment.

    &#34;&#34;&#34;
    def __init__(self, topic_model, experiment_id: str, save_path: str,
                 save_model_history: bool = False, save_experiment: bool = True,
                 tree: dict = None, models_info: dict = None, cubes: List[dict] = None,
                 low_memory: bool = False):
        &#34;&#34;&#34;
        Initialize stage, also used for loading and creating new experiments.

        Parameters
        ----------
        experiment_id : str
            experiment id
        save_path : str
            path to save the experiment
        topic_model : TopicModel or None
            if TopicModel - use initial topic_model or last topic_model
            if save_model_history is True 
            if None - create empty experiment
        save_model_history : bool
            if True - Experiment will save all information about previous
            models (before this topic_model). The typical use case than
            you want to apply cube that cannot be applied in old
            experiment, then you create new experiment that will save
            all necessary information and will be independent itself  
            if False - then topic model will be initial model (the first)
        tree : dict
            tree of the experiment. It is used for loading and creating non empty experiment
        models_info : dict
            keys are model ids, where values are model&#39;s description
        cubes : list of dict
            cubes that were used in the experiment
        low_memory : bool
            If true, models be transformed to dummies via `squeeze_models()`.
            Gradually, level by level.
            If false, models will be untouched, all data, including inner ARTM models,
            Phi, Theta matrices, stays.
            If one wants to use squeezed topic model as before (eg. call `topic_model.get_phi()`),
            its inner ARTM model should be restored first.
            See docstring for `TopicModel.make_dummy()` method for reference.
        &#34;&#34;&#34;  # noqa: W291

        if not isinstance(save_path, str):
            raise ValueError(&#34;Cannot create an Experiment with invalid save_path!&#34;)
        if not isinstance(experiment_id, str):
            raise ValueError(&#34;Cannot create an Experiment with invalid experiment_id!&#34;)

        self.experiment_id = experiment_id

        if os.path.exists(save_path) and save_experiment:
            folders = os.listdir(save_path)
            if experiment_id in folders:
                raise FileExistsError(
                    f&#34;In /{save_path} experiment {experiment_id} already exists&#34;
                )

        self.save_path = save_path

        # if you want to create an empty Experiment (only experiment_id and save_path must be known)
        if save_model_history:
            self._prune_experiment(topic_model)
        else:
            topic_model.model_id = START
            self.cubes = [
                {
                    &#39;action&#39;: &#39;start&#39;,
                    &#39;params&#39;: [topic_model.get_jsonable_from_parameters()],
                }
            ]
            self.criteria = [None]
            self.models_info = {
                START: topic_model.get_jsonable_from_parameters()
            }

            self.models = {
                START: topic_model,
            }
            topic_model.experiment = self
            self.tree = Tree()
            self.tree.add_model(topic_model)
            topic_model.save_parameters()

        if save_experiment:
            self.save()

        self.datasets = dict()

        self._low_memory = low_memory

    @property
    def depth(self):
        &#34;&#34;&#34;
        Returns depth of the tree.  
        Be careful, depth of the tree may not be the real experiment depth.

        &#34;&#34;&#34;  # noqa: W291
        return self.tree.get_depth()

    @property
    def root(self):
        &#34;&#34;&#34; &#34;&#34;&#34;
        return self.models[START]

    def _move_models(self, load_path, old_experiment_id):
        &#34;&#34;&#34;
        Moves models description to a new experiment.

        Parameters
        ----------
        load_path : str
            path to an old experiment
        old_experiment_id : str
            old experiment id

        &#34;&#34;&#34;
        path_from = f&#34;{load_path}/{old_experiment_id}&#34;
        path_to = f&#34;{self.save_path}/{self.experiment_id}&#34;
        if not os.path.exists(path_to):
            os.makedirs(path_to)
        for model_id in self.models_info:
            os_code = os.system(f&#34;cp -R {path_from}/{model_id} {path_to}/{model_id}&#34;)
            if os_code == 0:
                params = json.load(open(f&#34;{path_to}/{model_id}/params.json&#34;, &#34;r&#34;))
                params[&#34;experiment_id&#34;] = self.experiment_id
                json.dump(params, open(f&#34;{path_to}/{model_id}/params.json&#34;, &#34;w&#34;))

    def _prune_experiment(self, topic_model):
        &#34;&#34;&#34;
        Prunes old experiment. Creates new experiment with information from old experiment.

        Parameters
        ----------
        topic_model : TopicModel
            topic_model

        &#34;&#34;&#34;
        experiment = topic_model.experiment
        self.cubes = experiment.cubes[:topic_model.depth + 1]
        self.criteria = experiment.criteria[:topic_model.depth + 1]
        self.tree = experiment.tree.clone()
        self.tree.prune(topic_model.depth)
        self.models_info = dict()
        self.models = dict()
        for model_id in self.tree.get_model_ids():
            self.models_info[model_id] = experiment.models_info[model_id]
            self.models[model_id] = experiment.models[model_id]
        self._move_models(topic_model.experiment.save_path,
                          topic_model.experiment.experiment_id)
        topic_model.experiment = self

    def _recover_consistency(self, load_path):
        &#34;&#34;&#34;
        Recovers removed files and models descriptions.

        Parameters
        ----------
        load_path : str
            path to the experiment

        &#34;&#34;&#34;
        if load_path[-1] == &#34;/&#34;:
            load_path = load_path[:-1]
        if self.save_path != &#34;/&#34;.join(load_path.split(&#34;/&#34;)[:-1]):
            print(f&#34;This Experiment was replaced from {self.save_path}.&#34;, end=&#34; &#34;)
            self.save_path = &#34;/&#34;.join(load_path.split(&#34;/&#34;)[:-1])
            print(&#34;Parameter is updated.&#34;)
        if self.experiment_id != load_path.split(&#34;/&#34;)[-1]:
            print(f&#34;This Experiment was renamed to {load_path.split(&#39;/&#39;)[-1]}.&#34;, end=&#34; &#34;)
            self.experiment_id = load_path.split(&#34;/&#34;)[-1]
            for model_id in self.models_info.keys():
                self.models_info[model_id][&#34;experiment_id&#34;] = self.experiment_id
                model_save_path = f&#34;{self.save_path}/{self.experiment_id}/{model_id}&#34;
                if os.path.exists(model_save_path) \
                        and (&#34;params.json&#34; in os.listdir(model_save_path)):
                    params = self.models_info[model_id]
                    json.dump(params, open(f&#34;{model_save_path}/params.json&#34;, &#34;w&#34;),
                              default=transform_topic_model_description_to_jsonable)
            print(&#34;Parameter is updated.&#34;)

        experiment_save_path = f&#34;{self.save_path}/{self.experiment_id}&#34;
        files = os.listdir(experiment_save_path)
        if &#34;params.html&#34; not in files:
            print(&#34;The file params.html was removed. Recover...&#34;, end=&#34; &#34;)
            html = get_html(self,)
            with open(f&#34;{experiment_save_path}/params.html&#34;, &#34;w&#34;, encoding=&#39;utf-8&#39;) as f:
                f.write(html)
            print(&#34;Recovered.&#34;)
        for model_id in self.models_info:
            model_save_path = f&#34;{experiment_save_path}/{model_id}&#34;
            if model_id not in files:
                print(f&#34;The folder with {model_id} model was removed. &#34;
                      f&#34;Recover...&#34;,
                      end=&#34; &#34;)
                os.makedirs(model_save_path)
                params = self.models_info[model_id]
                json.dump(params, open(f&#34;{model_save_path}/params.json&#34;, &#34;w&#34;),
                          default=transform_topic_model_description_to_jsonable)
                print(&#34;Recovered.&#34;)
            else:
                model_files = os.listdir(model_save_path)
                if &#34;params.json&#34; not in model_files:
                    print(f&#34;The file params.json in {model_id} folder was removed. &#34;
                          f&#34;Recover...&#34;,
                          end=&#34; &#34;)
                    params = self.models_info[model_id]
                    json.dump(params, open(f&#34;{model_save_path}/params.json&#34;, &#34;w&#34;),
                              default=transform_topic_model_description_to_jsonable)
                    print(&#34;Recovered.&#34;)

    def get_params(self):
        &#34;&#34;&#34;
        Gets params of the experiment.

        Returns
        -------
        parameters : dict

        &#34;&#34;&#34;
        params = {&#34;save_path&#34;: self.save_path,
                  &#34;experiment_id&#34;: self.experiment_id,
                  &#34;models_info&#34;: self.models_info,
                  &#34;criteria&#34;: self.criteria,
                  &#34;tree&#34;: self.tree.tree,
                  &#34;depth&#34;: self.depth,
                  &#34;cubes&#34;: self.cubes}

        return params

    def add_model(self, topic_model):
        &#34;&#34;&#34;
        Adds model to the experiment.

        Parameters
        ----------
        topic_model : TopicModel
            topic model

        &#34;&#34;&#34;
        topic_model.experiment = self
        self.tree.add_model(topic_model)
        self.models_info[topic_model.model_id] = topic_model.get_parameters()
        self.models[topic_model.model_id] = topic_model
        self.save()

    def add_cube(self, cube):
        &#34;&#34;&#34;
        Adds cube to the experiment.

        Parameters
        ----------
        cube : dict
            cube&#39;s params

        &#34;&#34;&#34;
        self.cubes.append(cube)
        self.criteria.append(None)
        self.save()

    def add_dataset(self, dataset_id, dataset):
        &#34;&#34;&#34;
        Adds dataset to storage.

        Parameters
        ----------
        dataset_id : str
            id of dataset to save
        dataset : Dataset

        &#34;&#34;&#34;
        if dataset_id not in self.datasets:
            self.datasets[dataset_id] = dataset
        else:
            raise NameError(f&#39;Dataset with name {dataset_id} already exists in the experiment.&#39;)

    def remove_dataset(self, dataset_id):
        &#34;&#34;&#34;
        Removes dataset from storage.

        Parameters
        ----------
        dataset_id : str
            id of dataset to remove

        &#34;&#34;&#34;
        if dataset_id in self.datasets:
            del self.datasets[dataset_id]
        else:
            raise NameError(f&#39;There is no dataset with name {dataset_id} in this experiment.&#39;)

    @staticmethod
    def _load(load_path,
              experiment_id: str,
              save_path: str,
              tree: dict = None,
              models_info: dict = None,
              cubes: List[dict] = None,
              criteria: List[str] = None):
        &#34;&#34;&#34;
        Load helper.

        &#34;&#34;&#34;
        if criteria is None:
            criteria = [None]

        from .models import TopicModel

        root_model_save_path = os.path.join(load_path, START)
        root_model = TopicModel.load(root_model_save_path)
        experiment = Experiment(
            root_model,
            experiment_id=experiment_id,
            save_path=save_path,
            save_experiment=False)
        experiment.tree = Tree(tree=tree)
        experiment.models_info = models_info
        experiment.models = dict.fromkeys(experiment.tree.get_model_ids())
        experiment.models[START] = root_model
        experiment.cubes = cubes
        experiment.criteria = criteria

        return experiment

    def save_models(self, mode=&#39;all&#39;):
        &#34;&#34;&#34;
        Saves experiment models with respect to selected way of saving.

        Parameters
        ----------
        mode : str
            defines saving mode
            &#39;all&#39; - save all models in experiment  
            &#39;tree&#39; - save only stem and leaves from the last level  
            &#39;last&#39; save only leaves from the last level

        &#34;&#34;&#34;  # noqa: W291
        experiment_save_path = os.path.join(self.save_path, self.experiment_id)

        save_models = set()
        if mode == &#39;all&#39;:
            save_models.update([
                (tmodel, tmodel.model_id)
                for tmodel in self.models.values()
                if is_saveable_model(tmodel)
            ])
        elif mode == &#39;tree&#39;:
            save_models.update([
                (self.models.get(getattr(tmodel, &#39;parent_model_id&#39;, None)),
                 getattr(tmodel, &#39;parent_model_id&#39;, None))
                for tmodel in self.models.values()
                if is_saveable_model(self.models.get(getattr(tmodel, &#39;parent_model_id&#39;, None)))
            ])
        else:
            save_models.update(set([
                (tmodel, tmodel.model_id)
                for tmodel in self.get_models_by_depth(self.depth)
                if is_saveable_model(tmodel)
            ]))

        for model, model_id in list(save_models):
            model_save_path = os.path.join(experiment_save_path, model_id)
            model.save(model_save_path=model_save_path)

    def squeeze_models(self, depth: int = None):
        &#34;&#34;&#34;Transforms models to dummies so as to occupy less RAM memory

        Parameters
        ----------
        depth : int
            Models on what depth are to be squeezed, i.e. transformed to dummies
        &#34;&#34;&#34;
        if depth == 0:
            return

        assert abs(int(depth) - depth) == 0 and depth &gt; 0

        for m in self.get_models_by_depth(depth):
            m.make_dummy()

    def save(self, window_size: int = 1500, mode: str = &#39;all&#39;):
        &#34;&#34;&#34;
        Saves all params of the experiment to save_path/experiment_id.

        Parameters
        ----------
        window_size : int
            pixels size of window in html description (Default value = 1500)

        &#34;&#34;&#34;
        experiment_save_path = os.path.join(self.save_path, self.experiment_id)
        if not os.path.exists(experiment_save_path):
            os.makedirs(experiment_save_path)

        self.save_models(mode=mode)

        params = self.get_params()
        json.dump(params, open(f&#39;{experiment_save_path}/params.json&#39;, &#39;w&#39;),
                  default=transform_topic_model_description_to_jsonable)
        html = get_html(self, window_size)
        html_path = os.path.join(experiment_save_path, &#39;params.html&#39;)
        with open(html_path, &#34;w&#34;, encoding=&#39;utf-8&#39;) as f:
            f.write(html)

    @staticmethod
    def load(load_path):
        &#34;&#34;&#34;
        Loads all params of the experiments. Recovers removed files if it is possible.

        Parameters
        ----------
        load_path : str
            path to the experiment folder.

        Returns
        -------
        Experiment

        &#34;&#34;&#34;
        from .models import DummyTopicModel

        files = os.listdir(load_path)
        if &#34;params.json&#34; not in files:
            raise FileExistsError(&#34;The main file params.json does not exist.&#34;)
        else:
            params = json.load(open(f&#34;{load_path}/params.json&#34;, &#34;r&#34;))
            params.pop(&#39;depth&#39;, None)

            experiment = Experiment._load(load_path, **params)
            experiment._recover_consistency(load_path)

            for model_id in experiment.models.keys():
                if model_id != START:
                    model_save_path = os.path.join(load_path, model_id)
                    experiment.models[model_id] = DummyTopicModel.load(
                        model_save_path, experiment
                    )

        return experiment

    def get_description(self,
                        min_len_per_cube: int = MODEL_NAME_LENGTH,
                        len_tree_step: int = MODEL_NAME_LENGTH + 1):
        &#34;&#34;&#34;
        Creates description of the tree that you can print.
        Print is good when you use no more than 3 cubes at all.

        Parameters
        ----------
        min_len_per_cube : int
            minimal length of the one stage of experiment description
            (Default value = MODEL_NAME_LENGTH)
        len_tree_step : int
            length of the whole one stage description of experiment&#39;s tree
            (Default value = MODEL_NAME_LENGTH +1)

        Returns
        -------
        str
            description to print

        &#34;&#34;&#34;
        strings = give_strings_description(
            self,
            min_len_per_cube=min_len_per_cube,
            len_tree_step=len_tree_step
        )
        description = &#34;\n&#34;.join(strings)

        return description

    def show(self):
        &#34;&#34;&#34;
        Shows description of the experiment.

        &#34;&#34;&#34;
        nb_verbose = _run_from_notebook()
        string = self.get_description()
        Experiment._clear_and_print(string, nb_verbose)

    def get_models_by_depth(self, level=None):
        &#34;&#34;&#34; &#34;&#34;&#34;
        if level is None:
            # level = self.depth
            level = len(self.cubes)

        return [
            tmodel
            for tmodel in self.models.values()
            if isinstance(tmodel, BaseModel) and tmodel.depth == int(level)
        ]

    def select(self, query_string=&#39;&#39;, models_num=None, level=None):
        &#34;&#34;&#34;
        Selects all models satisfying the query string
        from all models on a particular depth.

        Parameters
        ----------
        query_string : str
            string of form &#34;SCORE1 &lt; VAL and SCORE2 &gt; VAL and SCORE3 -&gt; min&#34;
        models_num : int
            number of models to select (Default value = None)
        level : int
            None represents &#34;the last level of experiment&#34; (Default value = None)

        Returns
        -------
        result_topic_models : list of restored TopicModels

        String Format
        -------------
        string of following form:  
        QUERY = EXPR and EXPR and EXPR and ... and EXPR [collect COLLECT_NUMERAL]
        where EXPR could take any of these forms:  
            EXPR = LITERAL &lt; NUMBER  
            EXPR = LITERAL &gt; NUMBER  
            EXPR = LITERAL = NUMBER  
            EXPR = LITERAL -&gt; min  
            EXPR = LITERAL -&gt; max  
        and LITERAL is one of the following:
            SCORE_NAME or model.PARAMETER_NAME
            (for complicated scores you can use &#39;.&#39;: e.g. TopicKernelScore.average_purity)
        COLLECT clause is optional. COLLECT_NUMERAL could be integer or string &#34;all&#34;

        NUMBER is float / int or some expression involving special functions:
            MINIMUM, MAXIMUM, AVERAGE, MEDIAN
        Everything is separated by spaces.

        Notes
        -----

        If both models_num and COLLECT_NUMERAL is specified, COLLECT_NUMERAL takes priority.

        If optimization directive is specified, select() may return more models than requested
        (whether by models_num or by COLLECT_NUMERAL). This behaviour occurs when some scores
        are equal.

        For example, if we have 5 models with following scores:
            [model1: 100, model2: 95, model3: 95, model4: 95, model5: 80]
        and user asks experiment to provide 2 models with maximal score,
        then 4 models will be returned:
            [model1: 100, model2: 95, model3: 95, model4: 95]


        Examples
        --------

        &gt;&gt; experiment.select(&#34;PerplexityScore@words -&gt; min COLLECT 2&#34;)

        &gt;&gt; experiment.select(
            &#34;TopicKernelScore.average_contrast -&gt; max and PerplexityScore@all &lt; 100 COLLECT 2&#34;
        )

        &gt;&gt; experiment.select(
            &#34;PerplexityScore@words &lt; 1.1 * MINIMUM(PerplexityScore@all) and model.num_topics &gt; 12&#34;
        )


        &#34;&#34;&#34;  # noqa: W291
        from .models import DummyTopicModel
        models_num_as_parameter = models_num
        models_num_from_query = None
        candidate_tmodels = self.get_models_by_depth(level=level)

        if &#34;COLLECT&#34; in query_string:
            first_part, second_part = re.split(r&#39;\s*COLLECT\s+&#39;, query_string)

            if second_part.lower() != &#39;all&#39;:
                try:
                    models_num_from_query = int(second_part)
                except ValueError:
                    raise ValueError(f&#34;Invalid directive in COLLECT: {second_part}&#34;)
            else:
                models_num_from_query = len(candidate_tmodels)

            query_string = first_part

        models_num = choose_value_for_models_num_and_check(
            models_num_as_parameter, models_num_from_query
        )

        try:
            query_string = self.preprocess_query(query_string, level)
            req_lesser, req_greater, req_equal, metric, extremum = parse_query_string(query_string)

            result = choose_best_models(
                candidate_tmodels,
                req_lesser, req_greater, req_equal,
                metric, extremum,
                models_num
            )
            result_topic_models = [model.restore() if isinstance(model, DummyTopicModel)
                                   else model for model in result]
            return result_topic_models

        except ValueError as e:
            if e.args[0] not in EMPTY_ERRORS:
                raise e

            error_message = repr(e)
            warnings.warn(W_EMPTY_SPECIAL_1 + W_EMPTY_SPECIAL_2.format(error_message))

            return []

    def run(self, dataset, verbose=False, nb_verbose=False, restore_mode=False):  # noqa C901
        &#34;&#34;&#34;
        Runs defined pipeline and prints out the result.

        Parameters
        ----------
        dataset : Dataset
        verbose : bool
            parameter that determines if the output is produced (Default value = False)
        nb_verbose : bool
            parameter that determines where the output is produced 
            if False prints in console (Default value = False)

        &#34;&#34;&#34;  # noqa: W291
        stage_models = self.root

        for cube_index, cube_description in enumerate(self.cubes):
            if cube_description[&#39;action&#39;] == &#39;start&#39;:
                continue

            cube = cube_description[&#39;cube&#39;]
            if not restore_mode:
                cube(stage_models, dataset)
            else:
                if cube_index &lt; self.depth - 1:
                    print(f&#34;[Restoring experiment]: skipping cube {cube_index}&#34;)
                    continue
                if cube_index == self.depth - 1:
                    print(
                        f&#34;[Restoring experiment]: selecting models at cube number&#34;
                        f&#34;{cube_index} (some models could be lost)&#34;
                    )
                if cube_index &gt;= self.depth:
                    print(
                        f&#34;[Restoring experiment]: applying cube number {cube_index}&#34;
                    )
                    cube(stage_models, dataset)

            # TODO: either delete this line completely
            #  or come up with a way to restore any cube using just info about it in self.cubes
            #  (need to restore cubes for upgrading dummy to topic model)
            # self.cubes[cube_index].pop(&#39;cube&#39;, None)

            stage_models = self._select_and_save_unique_models(
                self.criteria[cube_index], dataset, cube_index + 1
            )

            if verbose:
                tree_description = &#34;\n&#34;.join(self.tree.get_description())
                Experiment._clear_and_print(tree_description, nb_verbose)

            if self._low_memory:
                self.squeeze_models(max(0, self.depth - 2))

        if verbose:
            Experiment._clear_and_print(self.get_description(), nb_verbose)

        if self._low_memory:
            self.squeeze_models(max(0, self.depth - 1))
            self.squeeze_models(self.depth)

        return stage_models

    @staticmethod
    def _clear_and_print(string, nb_verbose):
        if nb_verbose:
            from IPython.display import clear_output
            from IPython.core.display import display_pretty
            clear_output()
            display_pretty(string, raw=True)
        else:
            _ = os.system(&#39;cls&#39; if os.name == &#39;nt&#39; else &#39;clear&#39;)
            print(string)

    def _select_and_save_unique_models(self, templates, dataset, current_level):
        &#34;&#34;&#34;
        Applies selection criteria to
        last stage models and save successful candidates.

        Parameters
        ----------
        templates : list of str
        dataset : Dataset
        current_level : int

        Returns
        -------
        selected_models : set of TopicModel

        &#34;&#34;&#34;
        stage_models = sum(
            [self.select(template, level=current_level) for template in templates],
            []
        )
        number_models_selected = len(stage_models)
        stage_models = set(stage_models)
        if number_models_selected &gt; len(stage_models):
            warnings.warn(&#39;Some models satisfy multiple criteria&#39;)
        for model in stage_models:
            model.save(theta=True, dataset=dataset)
        return stage_models

    def describe_model(self, model_id):
        &#34;&#34;&#34;
        Returns all scores mentioned on the model stage criteria.

        Parameters
        ----------
        model_id : str
            string id of the model to examine

        Returns
        -------
        description_string : str
        &#34;&#34;&#34;
        model = self.models[model_id]
        # criteria for selecting models for the following cube
        templates = self.criteria[model.depth - 1]

        score_names = []
        for template in templates:
            score_names += [statement.split()[0] for statement in re.split(r&#39;\s+and\s+&#39;, template)]
        score_names = set(score_names)
        description_strings = [&#39;model: &#39; + model_id]
        for score_name in score_names:
            if &#39;model.&#39; in score_name:
                attr = score_name.split(&#39;.&#39;)[1]
                attr_val = getattr(model, attr)
                description_strings += [f&#39;model attribute &#34;{attr}&#34; with value: {attr_val}&#39;]
            else:
                try:
                    description_strings += [f&#39;{score_name}: {model.scores[score_name][-1]}&#39;]
                except KeyError:
                    raise ValueError(f&#39;Model does not have {score_name} score.&#39;)

        description_string = &#34;\n&#34;.join(description_strings)
        return description_string

    def preprocess_query(self, query_string: str, level):
        &#34;&#34;&#34;
        Preprocesses special queries with functions inside.

        Parameters
        ----------
        query_string : str
            string for processing
        level : int
            model level

        &#34;&#34;&#34;
        queries_list = re.split(r&#39;\s+and\s+&#39;, query_string)
        special_functions = [
                    &#39;MINIMUM&#39;,
                    &#39;MAXIMUM&#39;,
                    &#39;AVERAGE&#39;,
                    &#39;MEDIAN&#39;,
                ]

        model_queries = []
        special_queries = []
        standard_queries = []
        for query in queries_list:
            if query.startswith(&#39;model.&#39;):
                model_queries.append(query)
            elif any(special_function in query for special_function in special_functions):
                special_queries.append(query)
            else:
                standard_queries.append(query)

        if len(model_queries) != 0:
            inner_query_string = &#39; and &#39;.join(model_queries)
            (req_lesser, req_greater,
             req_equal, metric, extremum) = parse_query_string(inner_query_string)

            if metric is not None or extremum is not None:
                warnings.warn(&#39;You try to optimize model parameters.&#39;)

            candidate_tmodels = self.get_models_by_depth(level=level)
            special_models = choose_best_models(
                candidate_tmodels,
                req_lesser, req_greater, req_equal,
                metric, extremum,
                models_num=None
            )
        else:
            special_models = self.get_models_by_depth(level=level)

        special_queries = compute_special_queries(special_models, special_queries)

        return &#39; and &#39;.join(standard_queries + model_queries + special_queries)

    def build(self, settings):
        &#34;&#34;&#34;
        Builds experiment pipeline from description.

        Parameters
        ----------
        settings: list of dicts
            list with cubes parameters for every pipeline step
        Returns
        -------
        Nothing

        &#34;&#34;&#34;
        import topicnet.cooking_machine.cubes as tncubes

        self.criteria = [None]
        for stage in settings:
            for cube_name, cube_param in stage.items():
                if cube_name == &#39;selection&#39;:
                    stage_criteria = cube_param
                else:
                    try:
                        stage_cube = getattr(tncubes, cube_name)(**cube_param)
                    except Exception as e:
                        error_message = repr(e)
                        raise ValueError(f&#39;Can not create {cube_name} &#39;
                                         f&#39;with parameters {cube_param}.\n&#39;
                                         f&#39;Process failed with following: {error_message}&#39;)
            try:
                self.cubes += [{
                    &#39;action&#39;: stage_cube.action,
                    # TODO: should it be &#39;params&#39;: cube_param instead?
                    # it seems that it is possible to restore failed
                    # experiment with load() that way..?
                    &#39;params&#39;: stage_cube.get_jsonable_from_parameters(),
                    &#39;cube&#39;: stage_cube
                }]
                self.criteria.append(stage_criteria)
                del(stage_cube, stage_criteria)
            except NameError:
                raise NameError(&#39;To define pipeline BOTH cube and selection criteria needed&#39;)

    def set_criteria(self, cube_index, criteria):
        &#34;&#34;&#34;
        Allows to edit model selection criteria
        on each stage of the Experiment

        Parameters
        ----------
        cube_index : int
        selection_criteria: list of str or str
            the criteria to replacing current record

        Returns
        -------
        Nothing

        &#34;&#34;&#34;
        if cube_index &gt;= len(self.cubes):
            raise ValueError(f&#39;Invalid cube_index. There are {len(self.cubes)} cubes.&#39;
                             &#39;You can check it using experiment.cubes&#39;)
        else:
            if isinstance(criteria, str):
                criteria = [criteria]
            self.criteria[cube_index] = criteria</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="topicnet.cooking_machine.experiment.Experiment"><code class="flex name class">
<span>class <span class="ident">Experiment</span></span>
<span>(</span><span>topic_model, experiment_id, save_path, save_model_history=False, save_experiment=True, tree=None, models_info=None, cubes=None, low_memory=False)</span>
</code></dt>
<dd>
<section class="desc"><p>Contains experiment, its description and descriptions of all models in the experiment.</p>
<p>Initialize stage, also used for loading and creating new experiments.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>experiment_id</code></strong> :&ensp;<code>str</code></dt>
<dd>experiment id</dd>
<dt><strong><code>save_path</code></strong> :&ensp;<code>str</code></dt>
<dd>path to save the experiment</dd>
<dt><strong><code>topic_model</code></strong> :&ensp;<code>TopicModel</code> or <code>None</code></dt>
<dd>if TopicModel - use initial topic_model or last topic_model
if save_model_history is True
if None - create empty experiment</dd>
<dt><strong><code>save_model_history</code></strong> :&ensp;<code>bool</code></dt>
<dd>if True - Experiment will save all information about previous
models (before this topic_model). The typical use case than
you want to apply cube that cannot be applied in old
experiment, then you create new experiment that will save
all necessary information and will be independent itself<br>
if False - then topic model will be initial model (the first)</dd>
<dt><strong><code>tree</code></strong> :&ensp;<code>dict</code></dt>
<dd>tree of the experiment. It is used for loading and creating non empty experiment</dd>
<dt><strong><code>models_info</code></strong> :&ensp;<code>dict</code></dt>
<dd>keys are model ids, where values are model's description</dd>
<dt><strong><code>cubes</code></strong> :&ensp;<code>list</code> of <code>dict</code></dt>
<dd>cubes that were used in the experiment</dd>
<dt><strong><code>low_memory</code></strong> :&ensp;<code>bool</code></dt>
<dd>If true, models be transformed to dummies via <code>squeeze_models()</code>.
Gradually, level by level.
If false, models will be untouched, all data, including inner ARTM models,
Phi, Theta matrices, stays.
If one wants to use squeezed topic model as before (eg. call <code>topic_model.get_phi()</code>),
its inner ARTM model should be restored first.
See docstring for <code>TopicModel.make_dummy()</code> method for reference.</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">class Experiment(object):
    &#34;&#34;&#34;
    Contains experiment, its description and descriptions of all models in the experiment.

    &#34;&#34;&#34;
    def __init__(self, topic_model, experiment_id: str, save_path: str,
                 save_model_history: bool = False, save_experiment: bool = True,
                 tree: dict = None, models_info: dict = None, cubes: List[dict] = None,
                 low_memory: bool = False):
        &#34;&#34;&#34;
        Initialize stage, also used for loading and creating new experiments.

        Parameters
        ----------
        experiment_id : str
            experiment id
        save_path : str
            path to save the experiment
        topic_model : TopicModel or None
            if TopicModel - use initial topic_model or last topic_model
            if save_model_history is True 
            if None - create empty experiment
        save_model_history : bool
            if True - Experiment will save all information about previous
            models (before this topic_model). The typical use case than
            you want to apply cube that cannot be applied in old
            experiment, then you create new experiment that will save
            all necessary information and will be independent itself  
            if False - then topic model will be initial model (the first)
        tree : dict
            tree of the experiment. It is used for loading and creating non empty experiment
        models_info : dict
            keys are model ids, where values are model&#39;s description
        cubes : list of dict
            cubes that were used in the experiment
        low_memory : bool
            If true, models be transformed to dummies via `squeeze_models()`.
            Gradually, level by level.
            If false, models will be untouched, all data, including inner ARTM models,
            Phi, Theta matrices, stays.
            If one wants to use squeezed topic model as before (eg. call `topic_model.get_phi()`),
            its inner ARTM model should be restored first.
            See docstring for `TopicModel.make_dummy()` method for reference.
        &#34;&#34;&#34;  # noqa: W291

        if not isinstance(save_path, str):
            raise ValueError(&#34;Cannot create an Experiment with invalid save_path!&#34;)
        if not isinstance(experiment_id, str):
            raise ValueError(&#34;Cannot create an Experiment with invalid experiment_id!&#34;)

        self.experiment_id = experiment_id

        if os.path.exists(save_path) and save_experiment:
            folders = os.listdir(save_path)
            if experiment_id in folders:
                raise FileExistsError(
                    f&#34;In /{save_path} experiment {experiment_id} already exists&#34;
                )

        self.save_path = save_path

        # if you want to create an empty Experiment (only experiment_id and save_path must be known)
        if save_model_history:
            self._prune_experiment(topic_model)
        else:
            topic_model.model_id = START
            self.cubes = [
                {
                    &#39;action&#39;: &#39;start&#39;,
                    &#39;params&#39;: [topic_model.get_jsonable_from_parameters()],
                }
            ]
            self.criteria = [None]
            self.models_info = {
                START: topic_model.get_jsonable_from_parameters()
            }

            self.models = {
                START: topic_model,
            }
            topic_model.experiment = self
            self.tree = Tree()
            self.tree.add_model(topic_model)
            topic_model.save_parameters()

        if save_experiment:
            self.save()

        self.datasets = dict()

        self._low_memory = low_memory

    @property
    def depth(self):
        &#34;&#34;&#34;
        Returns depth of the tree.  
        Be careful, depth of the tree may not be the real experiment depth.

        &#34;&#34;&#34;  # noqa: W291
        return self.tree.get_depth()

    @property
    def root(self):
        &#34;&#34;&#34; &#34;&#34;&#34;
        return self.models[START]

    def _move_models(self, load_path, old_experiment_id):
        &#34;&#34;&#34;
        Moves models description to a new experiment.

        Parameters
        ----------
        load_path : str
            path to an old experiment
        old_experiment_id : str
            old experiment id

        &#34;&#34;&#34;
        path_from = f&#34;{load_path}/{old_experiment_id}&#34;
        path_to = f&#34;{self.save_path}/{self.experiment_id}&#34;
        if not os.path.exists(path_to):
            os.makedirs(path_to)
        for model_id in self.models_info:
            os_code = os.system(f&#34;cp -R {path_from}/{model_id} {path_to}/{model_id}&#34;)
            if os_code == 0:
                params = json.load(open(f&#34;{path_to}/{model_id}/params.json&#34;, &#34;r&#34;))
                params[&#34;experiment_id&#34;] = self.experiment_id
                json.dump(params, open(f&#34;{path_to}/{model_id}/params.json&#34;, &#34;w&#34;))

    def _prune_experiment(self, topic_model):
        &#34;&#34;&#34;
        Prunes old experiment. Creates new experiment with information from old experiment.

        Parameters
        ----------
        topic_model : TopicModel
            topic_model

        &#34;&#34;&#34;
        experiment = topic_model.experiment
        self.cubes = experiment.cubes[:topic_model.depth + 1]
        self.criteria = experiment.criteria[:topic_model.depth + 1]
        self.tree = experiment.tree.clone()
        self.tree.prune(topic_model.depth)
        self.models_info = dict()
        self.models = dict()
        for model_id in self.tree.get_model_ids():
            self.models_info[model_id] = experiment.models_info[model_id]
            self.models[model_id] = experiment.models[model_id]
        self._move_models(topic_model.experiment.save_path,
                          topic_model.experiment.experiment_id)
        topic_model.experiment = self

    def _recover_consistency(self, load_path):
        &#34;&#34;&#34;
        Recovers removed files and models descriptions.

        Parameters
        ----------
        load_path : str
            path to the experiment

        &#34;&#34;&#34;
        if load_path[-1] == &#34;/&#34;:
            load_path = load_path[:-1]
        if self.save_path != &#34;/&#34;.join(load_path.split(&#34;/&#34;)[:-1]):
            print(f&#34;This Experiment was replaced from {self.save_path}.&#34;, end=&#34; &#34;)
            self.save_path = &#34;/&#34;.join(load_path.split(&#34;/&#34;)[:-1])
            print(&#34;Parameter is updated.&#34;)
        if self.experiment_id != load_path.split(&#34;/&#34;)[-1]:
            print(f&#34;This Experiment was renamed to {load_path.split(&#39;/&#39;)[-1]}.&#34;, end=&#34; &#34;)
            self.experiment_id = load_path.split(&#34;/&#34;)[-1]
            for model_id in self.models_info.keys():
                self.models_info[model_id][&#34;experiment_id&#34;] = self.experiment_id
                model_save_path = f&#34;{self.save_path}/{self.experiment_id}/{model_id}&#34;
                if os.path.exists(model_save_path) \
                        and (&#34;params.json&#34; in os.listdir(model_save_path)):
                    params = self.models_info[model_id]
                    json.dump(params, open(f&#34;{model_save_path}/params.json&#34;, &#34;w&#34;),
                              default=transform_topic_model_description_to_jsonable)
            print(&#34;Parameter is updated.&#34;)

        experiment_save_path = f&#34;{self.save_path}/{self.experiment_id}&#34;
        files = os.listdir(experiment_save_path)
        if &#34;params.html&#34; not in files:
            print(&#34;The file params.html was removed. Recover...&#34;, end=&#34; &#34;)
            html = get_html(self,)
            with open(f&#34;{experiment_save_path}/params.html&#34;, &#34;w&#34;, encoding=&#39;utf-8&#39;) as f:
                f.write(html)
            print(&#34;Recovered.&#34;)
        for model_id in self.models_info:
            model_save_path = f&#34;{experiment_save_path}/{model_id}&#34;
            if model_id not in files:
                print(f&#34;The folder with {model_id} model was removed. &#34;
                      f&#34;Recover...&#34;,
                      end=&#34; &#34;)
                os.makedirs(model_save_path)
                params = self.models_info[model_id]
                json.dump(params, open(f&#34;{model_save_path}/params.json&#34;, &#34;w&#34;),
                          default=transform_topic_model_description_to_jsonable)
                print(&#34;Recovered.&#34;)
            else:
                model_files = os.listdir(model_save_path)
                if &#34;params.json&#34; not in model_files:
                    print(f&#34;The file params.json in {model_id} folder was removed. &#34;
                          f&#34;Recover...&#34;,
                          end=&#34; &#34;)
                    params = self.models_info[model_id]
                    json.dump(params, open(f&#34;{model_save_path}/params.json&#34;, &#34;w&#34;),
                              default=transform_topic_model_description_to_jsonable)
                    print(&#34;Recovered.&#34;)

    def get_params(self):
        &#34;&#34;&#34;
        Gets params of the experiment.

        Returns
        -------
        parameters : dict

        &#34;&#34;&#34;
        params = {&#34;save_path&#34;: self.save_path,
                  &#34;experiment_id&#34;: self.experiment_id,
                  &#34;models_info&#34;: self.models_info,
                  &#34;criteria&#34;: self.criteria,
                  &#34;tree&#34;: self.tree.tree,
                  &#34;depth&#34;: self.depth,
                  &#34;cubes&#34;: self.cubes}

        return params

    def add_model(self, topic_model):
        &#34;&#34;&#34;
        Adds model to the experiment.

        Parameters
        ----------
        topic_model : TopicModel
            topic model

        &#34;&#34;&#34;
        topic_model.experiment = self
        self.tree.add_model(topic_model)
        self.models_info[topic_model.model_id] = topic_model.get_parameters()
        self.models[topic_model.model_id] = topic_model
        self.save()

    def add_cube(self, cube):
        &#34;&#34;&#34;
        Adds cube to the experiment.

        Parameters
        ----------
        cube : dict
            cube&#39;s params

        &#34;&#34;&#34;
        self.cubes.append(cube)
        self.criteria.append(None)
        self.save()

    def add_dataset(self, dataset_id, dataset):
        &#34;&#34;&#34;
        Adds dataset to storage.

        Parameters
        ----------
        dataset_id : str
            id of dataset to save
        dataset : Dataset

        &#34;&#34;&#34;
        if dataset_id not in self.datasets:
            self.datasets[dataset_id] = dataset
        else:
            raise NameError(f&#39;Dataset with name {dataset_id} already exists in the experiment.&#39;)

    def remove_dataset(self, dataset_id):
        &#34;&#34;&#34;
        Removes dataset from storage.

        Parameters
        ----------
        dataset_id : str
            id of dataset to remove

        &#34;&#34;&#34;
        if dataset_id in self.datasets:
            del self.datasets[dataset_id]
        else:
            raise NameError(f&#39;There is no dataset with name {dataset_id} in this experiment.&#39;)

    @staticmethod
    def _load(load_path,
              experiment_id: str,
              save_path: str,
              tree: dict = None,
              models_info: dict = None,
              cubes: List[dict] = None,
              criteria: List[str] = None):
        &#34;&#34;&#34;
        Load helper.

        &#34;&#34;&#34;
        if criteria is None:
            criteria = [None]

        from .models import TopicModel

        root_model_save_path = os.path.join(load_path, START)
        root_model = TopicModel.load(root_model_save_path)
        experiment = Experiment(
            root_model,
            experiment_id=experiment_id,
            save_path=save_path,
            save_experiment=False)
        experiment.tree = Tree(tree=tree)
        experiment.models_info = models_info
        experiment.models = dict.fromkeys(experiment.tree.get_model_ids())
        experiment.models[START] = root_model
        experiment.cubes = cubes
        experiment.criteria = criteria

        return experiment

    def save_models(self, mode=&#39;all&#39;):
        &#34;&#34;&#34;
        Saves experiment models with respect to selected way of saving.

        Parameters
        ----------
        mode : str
            defines saving mode
            &#39;all&#39; - save all models in experiment  
            &#39;tree&#39; - save only stem and leaves from the last level  
            &#39;last&#39; save only leaves from the last level

        &#34;&#34;&#34;  # noqa: W291
        experiment_save_path = os.path.join(self.save_path, self.experiment_id)

        save_models = set()
        if mode == &#39;all&#39;:
            save_models.update([
                (tmodel, tmodel.model_id)
                for tmodel in self.models.values()
                if is_saveable_model(tmodel)
            ])
        elif mode == &#39;tree&#39;:
            save_models.update([
                (self.models.get(getattr(tmodel, &#39;parent_model_id&#39;, None)),
                 getattr(tmodel, &#39;parent_model_id&#39;, None))
                for tmodel in self.models.values()
                if is_saveable_model(self.models.get(getattr(tmodel, &#39;parent_model_id&#39;, None)))
            ])
        else:
            save_models.update(set([
                (tmodel, tmodel.model_id)
                for tmodel in self.get_models_by_depth(self.depth)
                if is_saveable_model(tmodel)
            ]))

        for model, model_id in list(save_models):
            model_save_path = os.path.join(experiment_save_path, model_id)
            model.save(model_save_path=model_save_path)

    def squeeze_models(self, depth: int = None):
        &#34;&#34;&#34;Transforms models to dummies so as to occupy less RAM memory

        Parameters
        ----------
        depth : int
            Models on what depth are to be squeezed, i.e. transformed to dummies
        &#34;&#34;&#34;
        if depth == 0:
            return

        assert abs(int(depth) - depth) == 0 and depth &gt; 0

        for m in self.get_models_by_depth(depth):
            m.make_dummy()

    def save(self, window_size: int = 1500, mode: str = &#39;all&#39;):
        &#34;&#34;&#34;
        Saves all params of the experiment to save_path/experiment_id.

        Parameters
        ----------
        window_size : int
            pixels size of window in html description (Default value = 1500)

        &#34;&#34;&#34;
        experiment_save_path = os.path.join(self.save_path, self.experiment_id)
        if not os.path.exists(experiment_save_path):
            os.makedirs(experiment_save_path)

        self.save_models(mode=mode)

        params = self.get_params()
        json.dump(params, open(f&#39;{experiment_save_path}/params.json&#39;, &#39;w&#39;),
                  default=transform_topic_model_description_to_jsonable)
        html = get_html(self, window_size)
        html_path = os.path.join(experiment_save_path, &#39;params.html&#39;)
        with open(html_path, &#34;w&#34;, encoding=&#39;utf-8&#39;) as f:
            f.write(html)

    @staticmethod
    def load(load_path):
        &#34;&#34;&#34;
        Loads all params of the experiments. Recovers removed files if it is possible.

        Parameters
        ----------
        load_path : str
            path to the experiment folder.

        Returns
        -------
        Experiment

        &#34;&#34;&#34;
        from .models import DummyTopicModel

        files = os.listdir(load_path)
        if &#34;params.json&#34; not in files:
            raise FileExistsError(&#34;The main file params.json does not exist.&#34;)
        else:
            params = json.load(open(f&#34;{load_path}/params.json&#34;, &#34;r&#34;))
            params.pop(&#39;depth&#39;, None)

            experiment = Experiment._load(load_path, **params)
            experiment._recover_consistency(load_path)

            for model_id in experiment.models.keys():
                if model_id != START:
                    model_save_path = os.path.join(load_path, model_id)
                    experiment.models[model_id] = DummyTopicModel.load(
                        model_save_path, experiment
                    )

        return experiment

    def get_description(self,
                        min_len_per_cube: int = MODEL_NAME_LENGTH,
                        len_tree_step: int = MODEL_NAME_LENGTH + 1):
        &#34;&#34;&#34;
        Creates description of the tree that you can print.
        Print is good when you use no more than 3 cubes at all.

        Parameters
        ----------
        min_len_per_cube : int
            minimal length of the one stage of experiment description
            (Default value = MODEL_NAME_LENGTH)
        len_tree_step : int
            length of the whole one stage description of experiment&#39;s tree
            (Default value = MODEL_NAME_LENGTH +1)

        Returns
        -------
        str
            description to print

        &#34;&#34;&#34;
        strings = give_strings_description(
            self,
            min_len_per_cube=min_len_per_cube,
            len_tree_step=len_tree_step
        )
        description = &#34;\n&#34;.join(strings)

        return description

    def show(self):
        &#34;&#34;&#34;
        Shows description of the experiment.

        &#34;&#34;&#34;
        nb_verbose = _run_from_notebook()
        string = self.get_description()
        Experiment._clear_and_print(string, nb_verbose)

    def get_models_by_depth(self, level=None):
        &#34;&#34;&#34; &#34;&#34;&#34;
        if level is None:
            # level = self.depth
            level = len(self.cubes)

        return [
            tmodel
            for tmodel in self.models.values()
            if isinstance(tmodel, BaseModel) and tmodel.depth == int(level)
        ]

    def select(self, query_string=&#39;&#39;, models_num=None, level=None):
        &#34;&#34;&#34;
        Selects all models satisfying the query string
        from all models on a particular depth.

        Parameters
        ----------
        query_string : str
            string of form &#34;SCORE1 &lt; VAL and SCORE2 &gt; VAL and SCORE3 -&gt; min&#34;
        models_num : int
            number of models to select (Default value = None)
        level : int
            None represents &#34;the last level of experiment&#34; (Default value = None)

        Returns
        -------
        result_topic_models : list of restored TopicModels

        String Format
        -------------
        string of following form:  
        QUERY = EXPR and EXPR and EXPR and ... and EXPR [collect COLLECT_NUMERAL]
        where EXPR could take any of these forms:  
            EXPR = LITERAL &lt; NUMBER  
            EXPR = LITERAL &gt; NUMBER  
            EXPR = LITERAL = NUMBER  
            EXPR = LITERAL -&gt; min  
            EXPR = LITERAL -&gt; max  
        and LITERAL is one of the following:
            SCORE_NAME or model.PARAMETER_NAME
            (for complicated scores you can use &#39;.&#39;: e.g. TopicKernelScore.average_purity)
        COLLECT clause is optional. COLLECT_NUMERAL could be integer or string &#34;all&#34;

        NUMBER is float / int or some expression involving special functions:
            MINIMUM, MAXIMUM, AVERAGE, MEDIAN
        Everything is separated by spaces.

        Notes
        -----

        If both models_num and COLLECT_NUMERAL is specified, COLLECT_NUMERAL takes priority.

        If optimization directive is specified, select() may return more models than requested
        (whether by models_num or by COLLECT_NUMERAL). This behaviour occurs when some scores
        are equal.

        For example, if we have 5 models with following scores:
            [model1: 100, model2: 95, model3: 95, model4: 95, model5: 80]
        and user asks experiment to provide 2 models with maximal score,
        then 4 models will be returned:
            [model1: 100, model2: 95, model3: 95, model4: 95]


        Examples
        --------

        &gt;&gt; experiment.select(&#34;PerplexityScore@words -&gt; min COLLECT 2&#34;)

        &gt;&gt; experiment.select(
            &#34;TopicKernelScore.average_contrast -&gt; max and PerplexityScore@all &lt; 100 COLLECT 2&#34;
        )

        &gt;&gt; experiment.select(
            &#34;PerplexityScore@words &lt; 1.1 * MINIMUM(PerplexityScore@all) and model.num_topics &gt; 12&#34;
        )


        &#34;&#34;&#34;  # noqa: W291
        from .models import DummyTopicModel
        models_num_as_parameter = models_num
        models_num_from_query = None
        candidate_tmodels = self.get_models_by_depth(level=level)

        if &#34;COLLECT&#34; in query_string:
            first_part, second_part = re.split(r&#39;\s*COLLECT\s+&#39;, query_string)

            if second_part.lower() != &#39;all&#39;:
                try:
                    models_num_from_query = int(second_part)
                except ValueError:
                    raise ValueError(f&#34;Invalid directive in COLLECT: {second_part}&#34;)
            else:
                models_num_from_query = len(candidate_tmodels)

            query_string = first_part

        models_num = choose_value_for_models_num_and_check(
            models_num_as_parameter, models_num_from_query
        )

        try:
            query_string = self.preprocess_query(query_string, level)
            req_lesser, req_greater, req_equal, metric, extremum = parse_query_string(query_string)

            result = choose_best_models(
                candidate_tmodels,
                req_lesser, req_greater, req_equal,
                metric, extremum,
                models_num
            )
            result_topic_models = [model.restore() if isinstance(model, DummyTopicModel)
                                   else model for model in result]
            return result_topic_models

        except ValueError as e:
            if e.args[0] not in EMPTY_ERRORS:
                raise e

            error_message = repr(e)
            warnings.warn(W_EMPTY_SPECIAL_1 + W_EMPTY_SPECIAL_2.format(error_message))

            return []

    def run(self, dataset, verbose=False, nb_verbose=False, restore_mode=False):  # noqa C901
        &#34;&#34;&#34;
        Runs defined pipeline and prints out the result.

        Parameters
        ----------
        dataset : Dataset
        verbose : bool
            parameter that determines if the output is produced (Default value = False)
        nb_verbose : bool
            parameter that determines where the output is produced 
            if False prints in console (Default value = False)

        &#34;&#34;&#34;  # noqa: W291
        stage_models = self.root

        for cube_index, cube_description in enumerate(self.cubes):
            if cube_description[&#39;action&#39;] == &#39;start&#39;:
                continue

            cube = cube_description[&#39;cube&#39;]
            if not restore_mode:
                cube(stage_models, dataset)
            else:
                if cube_index &lt; self.depth - 1:
                    print(f&#34;[Restoring experiment]: skipping cube {cube_index}&#34;)
                    continue
                if cube_index == self.depth - 1:
                    print(
                        f&#34;[Restoring experiment]: selecting models at cube number&#34;
                        f&#34;{cube_index} (some models could be lost)&#34;
                    )
                if cube_index &gt;= self.depth:
                    print(
                        f&#34;[Restoring experiment]: applying cube number {cube_index}&#34;
                    )
                    cube(stage_models, dataset)

            # TODO: either delete this line completely
            #  or come up with a way to restore any cube using just info about it in self.cubes
            #  (need to restore cubes for upgrading dummy to topic model)
            # self.cubes[cube_index].pop(&#39;cube&#39;, None)

            stage_models = self._select_and_save_unique_models(
                self.criteria[cube_index], dataset, cube_index + 1
            )

            if verbose:
                tree_description = &#34;\n&#34;.join(self.tree.get_description())
                Experiment._clear_and_print(tree_description, nb_verbose)

            if self._low_memory:
                self.squeeze_models(max(0, self.depth - 2))

        if verbose:
            Experiment._clear_and_print(self.get_description(), nb_verbose)

        if self._low_memory:
            self.squeeze_models(max(0, self.depth - 1))
            self.squeeze_models(self.depth)

        return stage_models

    @staticmethod
    def _clear_and_print(string, nb_verbose):
        if nb_verbose:
            from IPython.display import clear_output
            from IPython.core.display import display_pretty
            clear_output()
            display_pretty(string, raw=True)
        else:
            _ = os.system(&#39;cls&#39; if os.name == &#39;nt&#39; else &#39;clear&#39;)
            print(string)

    def _select_and_save_unique_models(self, templates, dataset, current_level):
        &#34;&#34;&#34;
        Applies selection criteria to
        last stage models and save successful candidates.

        Parameters
        ----------
        templates : list of str
        dataset : Dataset
        current_level : int

        Returns
        -------
        selected_models : set of TopicModel

        &#34;&#34;&#34;
        stage_models = sum(
            [self.select(template, level=current_level) for template in templates],
            []
        )
        number_models_selected = len(stage_models)
        stage_models = set(stage_models)
        if number_models_selected &gt; len(stage_models):
            warnings.warn(&#39;Some models satisfy multiple criteria&#39;)
        for model in stage_models:
            model.save(theta=True, dataset=dataset)
        return stage_models

    def describe_model(self, model_id):
        &#34;&#34;&#34;
        Returns all scores mentioned on the model stage criteria.

        Parameters
        ----------
        model_id : str
            string id of the model to examine

        Returns
        -------
        description_string : str
        &#34;&#34;&#34;
        model = self.models[model_id]
        # criteria for selecting models for the following cube
        templates = self.criteria[model.depth - 1]

        score_names = []
        for template in templates:
            score_names += [statement.split()[0] for statement in re.split(r&#39;\s+and\s+&#39;, template)]
        score_names = set(score_names)
        description_strings = [&#39;model: &#39; + model_id]
        for score_name in score_names:
            if &#39;model.&#39; in score_name:
                attr = score_name.split(&#39;.&#39;)[1]
                attr_val = getattr(model, attr)
                description_strings += [f&#39;model attribute &#34;{attr}&#34; with value: {attr_val}&#39;]
            else:
                try:
                    description_strings += [f&#39;{score_name}: {model.scores[score_name][-1]}&#39;]
                except KeyError:
                    raise ValueError(f&#39;Model does not have {score_name} score.&#39;)

        description_string = &#34;\n&#34;.join(description_strings)
        return description_string

    def preprocess_query(self, query_string: str, level):
        &#34;&#34;&#34;
        Preprocesses special queries with functions inside.

        Parameters
        ----------
        query_string : str
            string for processing
        level : int
            model level

        &#34;&#34;&#34;
        queries_list = re.split(r&#39;\s+and\s+&#39;, query_string)
        special_functions = [
                    &#39;MINIMUM&#39;,
                    &#39;MAXIMUM&#39;,
                    &#39;AVERAGE&#39;,
                    &#39;MEDIAN&#39;,
                ]

        model_queries = []
        special_queries = []
        standard_queries = []
        for query in queries_list:
            if query.startswith(&#39;model.&#39;):
                model_queries.append(query)
            elif any(special_function in query for special_function in special_functions):
                special_queries.append(query)
            else:
                standard_queries.append(query)

        if len(model_queries) != 0:
            inner_query_string = &#39; and &#39;.join(model_queries)
            (req_lesser, req_greater,
             req_equal, metric, extremum) = parse_query_string(inner_query_string)

            if metric is not None or extremum is not None:
                warnings.warn(&#39;You try to optimize model parameters.&#39;)

            candidate_tmodels = self.get_models_by_depth(level=level)
            special_models = choose_best_models(
                candidate_tmodels,
                req_lesser, req_greater, req_equal,
                metric, extremum,
                models_num=None
            )
        else:
            special_models = self.get_models_by_depth(level=level)

        special_queries = compute_special_queries(special_models, special_queries)

        return &#39; and &#39;.join(standard_queries + model_queries + special_queries)

    def build(self, settings):
        &#34;&#34;&#34;
        Builds experiment pipeline from description.

        Parameters
        ----------
        settings: list of dicts
            list with cubes parameters for every pipeline step
        Returns
        -------
        Nothing

        &#34;&#34;&#34;
        import topicnet.cooking_machine.cubes as tncubes

        self.criteria = [None]
        for stage in settings:
            for cube_name, cube_param in stage.items():
                if cube_name == &#39;selection&#39;:
                    stage_criteria = cube_param
                else:
                    try:
                        stage_cube = getattr(tncubes, cube_name)(**cube_param)
                    except Exception as e:
                        error_message = repr(e)
                        raise ValueError(f&#39;Can not create {cube_name} &#39;
                                         f&#39;with parameters {cube_param}.\n&#39;
                                         f&#39;Process failed with following: {error_message}&#39;)
            try:
                self.cubes += [{
                    &#39;action&#39;: stage_cube.action,
                    # TODO: should it be &#39;params&#39;: cube_param instead?
                    # it seems that it is possible to restore failed
                    # experiment with load() that way..?
                    &#39;params&#39;: stage_cube.get_jsonable_from_parameters(),
                    &#39;cube&#39;: stage_cube
                }]
                self.criteria.append(stage_criteria)
                del(stage_cube, stage_criteria)
            except NameError:
                raise NameError(&#39;To define pipeline BOTH cube and selection criteria needed&#39;)

    def set_criteria(self, cube_index, criteria):
        &#34;&#34;&#34;
        Allows to edit model selection criteria
        on each stage of the Experiment

        Parameters
        ----------
        cube_index : int
        selection_criteria: list of str or str
            the criteria to replacing current record

        Returns
        -------
        Nothing

        &#34;&#34;&#34;
        if cube_index &gt;= len(self.cubes):
            raise ValueError(f&#39;Invalid cube_index. There are {len(self.cubes)} cubes.&#39;
                             &#39;You can check it using experiment.cubes&#39;)
        else:
            if isinstance(criteria, str):
                criteria = [criteria]
            self.criteria[cube_index] = criteria</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="topicnet.cooking_machine.experiment.Experiment.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>load_path)</span>
</code></dt>
<dd>
<section class="desc"><p>Loads all params of the experiments. Recovers removed files if it is possible.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>load_path</code></strong> :&ensp;<code>str</code></dt>
<dd>path to the experiment folder.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><a title="topicnet.cooking_machine.experiment.Experiment" href="#topicnet.cooking_machine.experiment.Experiment"><code>Experiment</code></a></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">@staticmethod
def load(load_path):
    &#34;&#34;&#34;
    Loads all params of the experiments. Recovers removed files if it is possible.

    Parameters
    ----------
    load_path : str
        path to the experiment folder.

    Returns
    -------
    Experiment

    &#34;&#34;&#34;
    from .models import DummyTopicModel

    files = os.listdir(load_path)
    if &#34;params.json&#34; not in files:
        raise FileExistsError(&#34;The main file params.json does not exist.&#34;)
    else:
        params = json.load(open(f&#34;{load_path}/params.json&#34;, &#34;r&#34;))
        params.pop(&#39;depth&#39;, None)

        experiment = Experiment._load(load_path, **params)
        experiment._recover_consistency(load_path)

        for model_id in experiment.models.keys():
            if model_id != START:
                model_save_path = os.path.join(load_path, model_id)
                experiment.models[model_id] = DummyTopicModel.load(
                    model_save_path, experiment
                )

    return experiment</code></pre>
</details>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="topicnet.cooking_machine.experiment.Experiment.depth"><code class="name">var <span class="ident">depth</span></code></dt>
<dd>
<section class="desc"><p>Returns depth of the tree.<br>
Be careful, depth of the tree may not be the real experiment depth.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">@property
def depth(self):
    &#34;&#34;&#34;
    Returns depth of the tree.  
    Be careful, depth of the tree may not be the real experiment depth.

    &#34;&#34;&#34;  # noqa: W291
    return self.tree.get_depth()</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.root"><code class="name">var <span class="ident">root</span></code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">@property
def root(self):
    &#34;&#34;&#34; &#34;&#34;&#34;
    return self.models[START]</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="topicnet.cooking_machine.experiment.Experiment.add_cube"><code class="name flex">
<span>def <span class="ident">add_cube</span></span>(<span>self, cube)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds cube to the experiment.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>cube</code></strong> :&ensp;<code>dict</code></dt>
<dd>cube's params</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def add_cube(self, cube):
    &#34;&#34;&#34;
    Adds cube to the experiment.

    Parameters
    ----------
    cube : dict
        cube&#39;s params

    &#34;&#34;&#34;
    self.cubes.append(cube)
    self.criteria.append(None)
    self.save()</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.add_dataset"><code class="name flex">
<span>def <span class="ident">add_dataset</span></span>(<span>self, dataset_id, dataset)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds dataset to storage.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dataset_id</code></strong> :&ensp;<code>str</code></dt>
<dd>id of dataset to save</dd>
<dt><strong><code>dataset</code></strong> :&ensp;<code>Dataset</code></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def add_dataset(self, dataset_id, dataset):
    &#34;&#34;&#34;
    Adds dataset to storage.

    Parameters
    ----------
    dataset_id : str
        id of dataset to save
    dataset : Dataset

    &#34;&#34;&#34;
    if dataset_id not in self.datasets:
        self.datasets[dataset_id] = dataset
    else:
        raise NameError(f&#39;Dataset with name {dataset_id} already exists in the experiment.&#39;)</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.add_model"><code class="name flex">
<span>def <span class="ident">add_model</span></span>(<span>self, topic_model)</span>
</code></dt>
<dd>
<section class="desc"><p>Adds model to the experiment.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>topic_model</code></strong> :&ensp;<code>TopicModel</code></dt>
<dd>topic model</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def add_model(self, topic_model):
    &#34;&#34;&#34;
    Adds model to the experiment.

    Parameters
    ----------
    topic_model : TopicModel
        topic model

    &#34;&#34;&#34;
    topic_model.experiment = self
    self.tree.add_model(topic_model)
    self.models_info[topic_model.model_id] = topic_model.get_parameters()
    self.models[topic_model.model_id] = topic_model
    self.save()</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self, settings)</span>
</code></dt>
<dd>
<section class="desc"><p>Builds experiment pipeline from description.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>settings</code></strong> :&ensp;<code>list</code> of <code>dicts</code></dt>
<dd>list with cubes parameters for every pipeline step</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Nothing</code></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def build(self, settings):
    &#34;&#34;&#34;
    Builds experiment pipeline from description.

    Parameters
    ----------
    settings: list of dicts
        list with cubes parameters for every pipeline step
    Returns
    -------
    Nothing

    &#34;&#34;&#34;
    import topicnet.cooking_machine.cubes as tncubes

    self.criteria = [None]
    for stage in settings:
        for cube_name, cube_param in stage.items():
            if cube_name == &#39;selection&#39;:
                stage_criteria = cube_param
            else:
                try:
                    stage_cube = getattr(tncubes, cube_name)(**cube_param)
                except Exception as e:
                    error_message = repr(e)
                    raise ValueError(f&#39;Can not create {cube_name} &#39;
                                     f&#39;with parameters {cube_param}.\n&#39;
                                     f&#39;Process failed with following: {error_message}&#39;)
        try:
            self.cubes += [{
                &#39;action&#39;: stage_cube.action,
                # TODO: should it be &#39;params&#39;: cube_param instead?
                # it seems that it is possible to restore failed
                # experiment with load() that way..?
                &#39;params&#39;: stage_cube.get_jsonable_from_parameters(),
                &#39;cube&#39;: stage_cube
            }]
            self.criteria.append(stage_criteria)
            del(stage_cube, stage_criteria)
        except NameError:
            raise NameError(&#39;To define pipeline BOTH cube and selection criteria needed&#39;)</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.describe_model"><code class="name flex">
<span>def <span class="ident">describe_model</span></span>(<span>self, model_id)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns all scores mentioned on the model stage criteria.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model_id</code></strong> :&ensp;<code>str</code></dt>
<dd>string id of the model to examine</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>description_string</code></strong> :&ensp;<code>str</code></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def describe_model(self, model_id):
    &#34;&#34;&#34;
    Returns all scores mentioned on the model stage criteria.

    Parameters
    ----------
    model_id : str
        string id of the model to examine

    Returns
    -------
    description_string : str
    &#34;&#34;&#34;
    model = self.models[model_id]
    # criteria for selecting models for the following cube
    templates = self.criteria[model.depth - 1]

    score_names = []
    for template in templates:
        score_names += [statement.split()[0] for statement in re.split(r&#39;\s+and\s+&#39;, template)]
    score_names = set(score_names)
    description_strings = [&#39;model: &#39; + model_id]
    for score_name in score_names:
        if &#39;model.&#39; in score_name:
            attr = score_name.split(&#39;.&#39;)[1]
            attr_val = getattr(model, attr)
            description_strings += [f&#39;model attribute &#34;{attr}&#34; with value: {attr_val}&#39;]
        else:
            try:
                description_strings += [f&#39;{score_name}: {model.scores[score_name][-1]}&#39;]
            except KeyError:
                raise ValueError(f&#39;Model does not have {score_name} score.&#39;)

    description_string = &#34;\n&#34;.join(description_strings)
    return description_string</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.get_description"><code class="name flex">
<span>def <span class="ident">get_description</span></span>(<span>self, min_len_per_cube=26, len_tree_step=27)</span>
</code></dt>
<dd>
<section class="desc"><p>Creates description of the tree that you can print.
Print is good when you use no more than 3 cubes at all.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>min_len_per_cube</code></strong> :&ensp;<code>int</code></dt>
<dd>minimal length of the one stage of experiment description
(Default value = MODEL_NAME_LENGTH)</dd>
<dt><strong><code>len_tree_step</code></strong> :&ensp;<code>int</code></dt>
<dd>length of the whole one stage description of experiment's tree
(Default value = MODEL_NAME_LENGTH +1)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>description to print</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_description(self,
                    min_len_per_cube: int = MODEL_NAME_LENGTH,
                    len_tree_step: int = MODEL_NAME_LENGTH + 1):
    &#34;&#34;&#34;
    Creates description of the tree that you can print.
    Print is good when you use no more than 3 cubes at all.

    Parameters
    ----------
    min_len_per_cube : int
        minimal length of the one stage of experiment description
        (Default value = MODEL_NAME_LENGTH)
    len_tree_step : int
        length of the whole one stage description of experiment&#39;s tree
        (Default value = MODEL_NAME_LENGTH +1)

    Returns
    -------
    str
        description to print

    &#34;&#34;&#34;
    strings = give_strings_description(
        self,
        min_len_per_cube=min_len_per_cube,
        len_tree_step=len_tree_step
    )
    description = &#34;\n&#34;.join(strings)

    return description</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.get_models_by_depth"><code class="name flex">
<span>def <span class="ident">get_models_by_depth</span></span>(<span>self, level=None)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_models_by_depth(self, level=None):
    &#34;&#34;&#34; &#34;&#34;&#34;
    if level is None:
        # level = self.depth
        level = len(self.cubes)

    return [
        tmodel
        for tmodel in self.models.values()
        if isinstance(tmodel, BaseModel) and tmodel.depth == int(level)
    ]</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.get_params"><code class="name flex">
<span>def <span class="ident">get_params</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Gets params of the experiment.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>parameters</code></strong> :&ensp;<code>dict</code></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_params(self):
    &#34;&#34;&#34;
    Gets params of the experiment.

    Returns
    -------
    parameters : dict

    &#34;&#34;&#34;
    params = {&#34;save_path&#34;: self.save_path,
              &#34;experiment_id&#34;: self.experiment_id,
              &#34;models_info&#34;: self.models_info,
              &#34;criteria&#34;: self.criteria,
              &#34;tree&#34;: self.tree.tree,
              &#34;depth&#34;: self.depth,
              &#34;cubes&#34;: self.cubes}

    return params</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.preprocess_query"><code class="name flex">
<span>def <span class="ident">preprocess_query</span></span>(<span>self, query_string, level)</span>
</code></dt>
<dd>
<section class="desc"><p>Preprocesses special queries with functions inside.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>query_string</code></strong> :&ensp;<code>str</code></dt>
<dd>string for processing</dd>
<dt><strong><code>level</code></strong> :&ensp;<code>int</code></dt>
<dd>model level</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def preprocess_query(self, query_string: str, level):
    &#34;&#34;&#34;
    Preprocesses special queries with functions inside.

    Parameters
    ----------
    query_string : str
        string for processing
    level : int
        model level

    &#34;&#34;&#34;
    queries_list = re.split(r&#39;\s+and\s+&#39;, query_string)
    special_functions = [
                &#39;MINIMUM&#39;,
                &#39;MAXIMUM&#39;,
                &#39;AVERAGE&#39;,
                &#39;MEDIAN&#39;,
            ]

    model_queries = []
    special_queries = []
    standard_queries = []
    for query in queries_list:
        if query.startswith(&#39;model.&#39;):
            model_queries.append(query)
        elif any(special_function in query for special_function in special_functions):
            special_queries.append(query)
        else:
            standard_queries.append(query)

    if len(model_queries) != 0:
        inner_query_string = &#39; and &#39;.join(model_queries)
        (req_lesser, req_greater,
         req_equal, metric, extremum) = parse_query_string(inner_query_string)

        if metric is not None or extremum is not None:
            warnings.warn(&#39;You try to optimize model parameters.&#39;)

        candidate_tmodels = self.get_models_by_depth(level=level)
        special_models = choose_best_models(
            candidate_tmodels,
            req_lesser, req_greater, req_equal,
            metric, extremum,
            models_num=None
        )
    else:
        special_models = self.get_models_by_depth(level=level)

    special_queries = compute_special_queries(special_models, special_queries)

    return &#39; and &#39;.join(standard_queries + model_queries + special_queries)</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.remove_dataset"><code class="name flex">
<span>def <span class="ident">remove_dataset</span></span>(<span>self, dataset_id)</span>
</code></dt>
<dd>
<section class="desc"><p>Removes dataset from storage.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dataset_id</code></strong> :&ensp;<code>str</code></dt>
<dd>id of dataset to remove</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def remove_dataset(self, dataset_id):
    &#34;&#34;&#34;
    Removes dataset from storage.

    Parameters
    ----------
    dataset_id : str
        id of dataset to remove

    &#34;&#34;&#34;
    if dataset_id in self.datasets:
        del self.datasets[dataset_id]
    else:
        raise NameError(f&#39;There is no dataset with name {dataset_id} in this experiment.&#39;)</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self, dataset, verbose=False, nb_verbose=False, restore_mode=False)</span>
</code></dt>
<dd>
<section class="desc"><p>Runs defined pipeline and prints out the result.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dataset</code></strong> :&ensp;<code>Dataset</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code></dt>
<dd>parameter that determines if the output is produced (Default value = False)</dd>
<dt><strong><code>nb_verbose</code></strong> :&ensp;<code>bool</code></dt>
<dd>parameter that determines where the output is produced
if False prints in console (Default value = False)</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def run(self, dataset, verbose=False, nb_verbose=False, restore_mode=False):  # noqa C901
    &#34;&#34;&#34;
    Runs defined pipeline and prints out the result.

    Parameters
    ----------
    dataset : Dataset
    verbose : bool
        parameter that determines if the output is produced (Default value = False)
    nb_verbose : bool
        parameter that determines where the output is produced 
        if False prints in console (Default value = False)

    &#34;&#34;&#34;  # noqa: W291
    stage_models = self.root

    for cube_index, cube_description in enumerate(self.cubes):
        if cube_description[&#39;action&#39;] == &#39;start&#39;:
            continue

        cube = cube_description[&#39;cube&#39;]
        if not restore_mode:
            cube(stage_models, dataset)
        else:
            if cube_index &lt; self.depth - 1:
                print(f&#34;[Restoring experiment]: skipping cube {cube_index}&#34;)
                continue
            if cube_index == self.depth - 1:
                print(
                    f&#34;[Restoring experiment]: selecting models at cube number&#34;
                    f&#34;{cube_index} (some models could be lost)&#34;
                )
            if cube_index &gt;= self.depth:
                print(
                    f&#34;[Restoring experiment]: applying cube number {cube_index}&#34;
                )
                cube(stage_models, dataset)

        # TODO: either delete this line completely
        #  or come up with a way to restore any cube using just info about it in self.cubes
        #  (need to restore cubes for upgrading dummy to topic model)
        # self.cubes[cube_index].pop(&#39;cube&#39;, None)

        stage_models = self._select_and_save_unique_models(
            self.criteria[cube_index], dataset, cube_index + 1
        )

        if verbose:
            tree_description = &#34;\n&#34;.join(self.tree.get_description())
            Experiment._clear_and_print(tree_description, nb_verbose)

        if self._low_memory:
            self.squeeze_models(max(0, self.depth - 2))

    if verbose:
        Experiment._clear_and_print(self.get_description(), nb_verbose)

    if self._low_memory:
        self.squeeze_models(max(0, self.depth - 1))
        self.squeeze_models(self.depth)

    return stage_models</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, window_size=1500, mode='all')</span>
</code></dt>
<dd>
<section class="desc"><p>Saves all params of the experiment to save_path/experiment_id.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>window_size</code></strong> :&ensp;<code>int</code></dt>
<dd>pixels size of window in html description (Default value = 1500)</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def save(self, window_size: int = 1500, mode: str = &#39;all&#39;):
    &#34;&#34;&#34;
    Saves all params of the experiment to save_path/experiment_id.

    Parameters
    ----------
    window_size : int
        pixels size of window in html description (Default value = 1500)

    &#34;&#34;&#34;
    experiment_save_path = os.path.join(self.save_path, self.experiment_id)
    if not os.path.exists(experiment_save_path):
        os.makedirs(experiment_save_path)

    self.save_models(mode=mode)

    params = self.get_params()
    json.dump(params, open(f&#39;{experiment_save_path}/params.json&#39;, &#39;w&#39;),
              default=transform_topic_model_description_to_jsonable)
    html = get_html(self, window_size)
    html_path = os.path.join(experiment_save_path, &#39;params.html&#39;)
    with open(html_path, &#34;w&#34;, encoding=&#39;utf-8&#39;) as f:
        f.write(html)</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.save_models"><code class="name flex">
<span>def <span class="ident">save_models</span></span>(<span>self, mode='all')</span>
</code></dt>
<dd>
<section class="desc"><p>Saves experiment models with respect to selected way of saving.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>mode</code></strong> :&ensp;<code>str</code></dt>
<dd>defines saving mode
'all' - save all models in experiment<br>
'tree' - save only stem and leaves from the last level<br>
'last' save only leaves from the last level</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def save_models(self, mode=&#39;all&#39;):
    &#34;&#34;&#34;
    Saves experiment models with respect to selected way of saving.

    Parameters
    ----------
    mode : str
        defines saving mode
        &#39;all&#39; - save all models in experiment  
        &#39;tree&#39; - save only stem and leaves from the last level  
        &#39;last&#39; save only leaves from the last level

    &#34;&#34;&#34;  # noqa: W291
    experiment_save_path = os.path.join(self.save_path, self.experiment_id)

    save_models = set()
    if mode == &#39;all&#39;:
        save_models.update([
            (tmodel, tmodel.model_id)
            for tmodel in self.models.values()
            if is_saveable_model(tmodel)
        ])
    elif mode == &#39;tree&#39;:
        save_models.update([
            (self.models.get(getattr(tmodel, &#39;parent_model_id&#39;, None)),
             getattr(tmodel, &#39;parent_model_id&#39;, None))
            for tmodel in self.models.values()
            if is_saveable_model(self.models.get(getattr(tmodel, &#39;parent_model_id&#39;, None)))
        ])
    else:
        save_models.update(set([
            (tmodel, tmodel.model_id)
            for tmodel in self.get_models_by_depth(self.depth)
            if is_saveable_model(tmodel)
        ]))

    for model, model_id in list(save_models):
        model_save_path = os.path.join(experiment_save_path, model_id)
        model.save(model_save_path=model_save_path)</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.select"><code class="name flex">
<span>def <span class="ident">select</span></span>(<span>self, query_string='', models_num=None, level=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Selects all models satisfying the query string
from all models on a particular depth.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>query_string</code></strong> :&ensp;<code>str</code></dt>
<dd>string of form "SCORE1 &lt; VAL and SCORE2 &gt; VAL and SCORE3 -&gt; min"</dd>
<dt><strong><code>models_num</code></strong> :&ensp;<code>int</code></dt>
<dd>number of models to select (Default value = None)</dd>
<dt><strong><code>level</code></strong> :&ensp;<code>int</code></dt>
<dd>None represents "the last level of experiment" (Default value = None)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>result_topic_models</code></strong> :&ensp;<code>list</code> of <code>restored</code> <code>TopicModels</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="string-format">String Format</h2>
<p>string of following form:<br>
QUERY = EXPR and EXPR and EXPR and &hellip; and EXPR [collect COLLECT_NUMERAL]
where EXPR could take any of these forms:<br>
EXPR = LITERAL &lt; NUMBER<br>
EXPR = LITERAL &gt; NUMBER<br>
EXPR = LITERAL = NUMBER<br>
EXPR = LITERAL -&gt; min<br>
EXPR = LITERAL -&gt; max<br>
and LITERAL is one of the following:
SCORE_NAME or model.PARAMETER_NAME
(for complicated scores you can use '.': e.g. TopicKernelScore.average_purity)
COLLECT clause is optional. COLLECT_NUMERAL could be integer or string "all"</p>
<p>NUMBER is float / int or some expression involving special functions:
MINIMUM, MAXIMUM, AVERAGE, MEDIAN
Everything is separated by spaces.</p>
<h2 id="notes">Notes</h2>
<p>If both models_num and COLLECT_NUMERAL is specified, COLLECT_NUMERAL takes priority.</p>
<p>If optimization directive is specified, select() may return more models than requested
(whether by models_num or by COLLECT_NUMERAL). This behaviour occurs when some scores
are equal.</p>
<p>For example, if we have 5 models with following scores:
[model1: 100, model2: 95, model3: 95, model4: 95, model5: 80]
and user asks experiment to provide 2 models with maximal score,
then 4 models will be returned:
[model1: 100, model2: 95, model3: 95, model4: 95]</p>
<h2 id="examples">Examples</h2>
<blockquote>
<blockquote>
<p>experiment.select("PerplexityScore@words -&gt; min COLLECT 2")</p>
<p>experiment.select(
"TopicKernelScore.average_contrast -&gt; max and PerplexityScore@all &lt; 100 COLLECT 2"
)</p>
<p>experiment.select(
"PerplexityScore@words &lt; 1.1 * MINIMUM(PerplexityScore@all) and model.num_topics &gt; 12"
)</p>
</blockquote>
</blockquote></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def select(self, query_string=&#39;&#39;, models_num=None, level=None):
    &#34;&#34;&#34;
    Selects all models satisfying the query string
    from all models on a particular depth.

    Parameters
    ----------
    query_string : str
        string of form &#34;SCORE1 &lt; VAL and SCORE2 &gt; VAL and SCORE3 -&gt; min&#34;
    models_num : int
        number of models to select (Default value = None)
    level : int
        None represents &#34;the last level of experiment&#34; (Default value = None)

    Returns
    -------
    result_topic_models : list of restored TopicModels

    String Format
    -------------
    string of following form:  
    QUERY = EXPR and EXPR and EXPR and ... and EXPR [collect COLLECT_NUMERAL]
    where EXPR could take any of these forms:  
        EXPR = LITERAL &lt; NUMBER  
        EXPR = LITERAL &gt; NUMBER  
        EXPR = LITERAL = NUMBER  
        EXPR = LITERAL -&gt; min  
        EXPR = LITERAL -&gt; max  
    and LITERAL is one of the following:
        SCORE_NAME or model.PARAMETER_NAME
        (for complicated scores you can use &#39;.&#39;: e.g. TopicKernelScore.average_purity)
    COLLECT clause is optional. COLLECT_NUMERAL could be integer or string &#34;all&#34;

    NUMBER is float / int or some expression involving special functions:
        MINIMUM, MAXIMUM, AVERAGE, MEDIAN
    Everything is separated by spaces.

    Notes
    -----

    If both models_num and COLLECT_NUMERAL is specified, COLLECT_NUMERAL takes priority.

    If optimization directive is specified, select() may return more models than requested
    (whether by models_num or by COLLECT_NUMERAL). This behaviour occurs when some scores
    are equal.

    For example, if we have 5 models with following scores:
        [model1: 100, model2: 95, model3: 95, model4: 95, model5: 80]
    and user asks experiment to provide 2 models with maximal score,
    then 4 models will be returned:
        [model1: 100, model2: 95, model3: 95, model4: 95]


    Examples
    --------

    &gt;&gt; experiment.select(&#34;PerplexityScore@words -&gt; min COLLECT 2&#34;)

    &gt;&gt; experiment.select(
        &#34;TopicKernelScore.average_contrast -&gt; max and PerplexityScore@all &lt; 100 COLLECT 2&#34;
    )

    &gt;&gt; experiment.select(
        &#34;PerplexityScore@words &lt; 1.1 * MINIMUM(PerplexityScore@all) and model.num_topics &gt; 12&#34;
    )


    &#34;&#34;&#34;  # noqa: W291
    from .models import DummyTopicModel
    models_num_as_parameter = models_num
    models_num_from_query = None
    candidate_tmodels = self.get_models_by_depth(level=level)

    if &#34;COLLECT&#34; in query_string:
        first_part, second_part = re.split(r&#39;\s*COLLECT\s+&#39;, query_string)

        if second_part.lower() != &#39;all&#39;:
            try:
                models_num_from_query = int(second_part)
            except ValueError:
                raise ValueError(f&#34;Invalid directive in COLLECT: {second_part}&#34;)
        else:
            models_num_from_query = len(candidate_tmodels)

        query_string = first_part

    models_num = choose_value_for_models_num_and_check(
        models_num_as_parameter, models_num_from_query
    )

    try:
        query_string = self.preprocess_query(query_string, level)
        req_lesser, req_greater, req_equal, metric, extremum = parse_query_string(query_string)

        result = choose_best_models(
            candidate_tmodels,
            req_lesser, req_greater, req_equal,
            metric, extremum,
            models_num
        )
        result_topic_models = [model.restore() if isinstance(model, DummyTopicModel)
                               else model for model in result]
        return result_topic_models

    except ValueError as e:
        if e.args[0] not in EMPTY_ERRORS:
            raise e

        error_message = repr(e)
        warnings.warn(W_EMPTY_SPECIAL_1 + W_EMPTY_SPECIAL_2.format(error_message))

        return []</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.set_criteria"><code class="name flex">
<span>def <span class="ident">set_criteria</span></span>(<span>self, cube_index, criteria)</span>
</code></dt>
<dd>
<section class="desc"><p>Allows to edit model selection criteria
on each stage of the Experiment</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>cube_index</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>selection_criteria</code></strong> :&ensp;<code>list</code> of <code>str</code> or <code>str</code></dt>
<dd>the criteria to replacing current record</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Nothing</code></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def set_criteria(self, cube_index, criteria):
    &#34;&#34;&#34;
    Allows to edit model selection criteria
    on each stage of the Experiment

    Parameters
    ----------
    cube_index : int
    selection_criteria: list of str or str
        the criteria to replacing current record

    Returns
    -------
    Nothing

    &#34;&#34;&#34;
    if cube_index &gt;= len(self.cubes):
        raise ValueError(f&#39;Invalid cube_index. There are {len(self.cubes)} cubes.&#39;
                         &#39;You can check it using experiment.cubes&#39;)
    else:
        if isinstance(criteria, str):
            criteria = [criteria]
        self.criteria[cube_index] = criteria</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.show"><code class="name flex">
<span>def <span class="ident">show</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Shows description of the experiment.</p></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def show(self):
    &#34;&#34;&#34;
    Shows description of the experiment.

    &#34;&#34;&#34;
    nb_verbose = _run_from_notebook()
    string = self.get_description()
    Experiment._clear_and_print(string, nb_verbose)</code></pre>
</details>
</dd>
<dt id="topicnet.cooking_machine.experiment.Experiment.squeeze_models"><code class="name flex">
<span>def <span class="ident">squeeze_models</span></span>(<span>self, depth=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Transforms models to dummies so as to occupy less RAM memory</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>depth</code></strong> :&ensp;<code>int</code></dt>
<dd>Models on what depth are to be squeezed, i.e. transformed to dummies</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def squeeze_models(self, depth: int = None):
    &#34;&#34;&#34;Transforms models to dummies so as to occupy less RAM memory

    Parameters
    ----------
    depth : int
        Models on what depth are to be squeezed, i.e. transformed to dummies
    &#34;&#34;&#34;
    if depth == 0:
        return

    assert abs(int(depth) - depth) == 0 and depth &gt; 0

    for m in self.get_models_by_depth(depth):
        m.make_dummy()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="topicnet.cooking_machine" href="index.html">topicnet.cooking_machine</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="topicnet.cooking_machine.experiment.Experiment" href="#topicnet.cooking_machine.experiment.Experiment">Experiment</a></code></h4>
<ul class="two-column">
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.add_cube" href="#topicnet.cooking_machine.experiment.Experiment.add_cube">add_cube</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.add_dataset" href="#topicnet.cooking_machine.experiment.Experiment.add_dataset">add_dataset</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.add_model" href="#topicnet.cooking_machine.experiment.Experiment.add_model">add_model</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.build" href="#topicnet.cooking_machine.experiment.Experiment.build">build</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.depth" href="#topicnet.cooking_machine.experiment.Experiment.depth">depth</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.describe_model" href="#topicnet.cooking_machine.experiment.Experiment.describe_model">describe_model</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.get_description" href="#topicnet.cooking_machine.experiment.Experiment.get_description">get_description</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.get_models_by_depth" href="#topicnet.cooking_machine.experiment.Experiment.get_models_by_depth">get_models_by_depth</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.get_params" href="#topicnet.cooking_machine.experiment.Experiment.get_params">get_params</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.load" href="#topicnet.cooking_machine.experiment.Experiment.load">load</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.preprocess_query" href="#topicnet.cooking_machine.experiment.Experiment.preprocess_query">preprocess_query</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.remove_dataset" href="#topicnet.cooking_machine.experiment.Experiment.remove_dataset">remove_dataset</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.root" href="#topicnet.cooking_machine.experiment.Experiment.root">root</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.run" href="#topicnet.cooking_machine.experiment.Experiment.run">run</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.save" href="#topicnet.cooking_machine.experiment.Experiment.save">save</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.save_models" href="#topicnet.cooking_machine.experiment.Experiment.save_models">save_models</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.select" href="#topicnet.cooking_machine.experiment.Experiment.select">select</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.set_criteria" href="#topicnet.cooking_machine.experiment.Experiment.set_criteria">set_criteria</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.show" href="#topicnet.cooking_machine.experiment.Experiment.show">show</a></code></li>
<li><code><a title="topicnet.cooking_machine.experiment.Experiment.squeeze_models" href="#topicnet.cooking_machine.experiment.Experiment.squeeze_models">squeeze_models</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.6.3</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>