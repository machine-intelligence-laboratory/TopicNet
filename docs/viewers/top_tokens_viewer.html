<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.2" />
<title>topicnet.viewers.top_tokens_viewer API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>topicnet.viewers.top_tokens_viewer</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from typing import Dict, Iterator, List, Tuple, Union
import warnings

from .base_viewer import BaseViewer


def get_top_values(values, top_number, return_indexes=True):
    &#34;&#34;&#34;
    Returns top_number top values from the matrix for each column.

    Parameters
    ----------
    values : np.array
        a two dimensional array of values
    top_number : int
        number of top values to return
    return_indexes : bool
        a flag to return indexes together with the top values

    Returns
    -------
    top_values : nd.array
        array of top_number top values for each column of the initial array
    (optional) top_indexes : nd.array
        array of original indexes for top_values array (Default value = True)

    &#34;&#34;&#34;
    if top_number &gt; len(values):
        top_number = len(values)
        warnings.warn(&#39;num_top_tokens greater than modality size&#39;, UserWarning)

    top_indexes = np.argpartition(
        values, len(values) - top_number
    )[-top_number:]

    top_values = values[top_indexes]
    sorted_top_values_indexes = top_values.argsort()[::-1]

    top_values = top_values[sorted_top_values_indexes]

    # get initial indexes
    top_indexes = top_indexes[sorted_top_values_indexes]

    if return_indexes:
        return top_values, top_indexes

    return top_values


def compute_pt_distribution(model, class_ids=None):
    &#34;&#34;&#34;
    Calculates the Prob(t) vector (vector contains an entry for each topic).

    Parameters
    ----------
    model : TopicModel
        model under the scope
    class_ids : list of str or None
        list of modalities to consider, which takes all modalities in the model
        (Default value = None)

    Returns
    -------
    float
        probability that a random token from the collection belongs to that topic

    &#34;&#34;&#34;

    n_wt = model.get_phi(class_ids=class_ids, model_name=model.model_nwt)
    n_t = n_wt.sum(axis=0)  # sum over all words
    # TODO: maybe this is not P(t)
    #  P(t) means prior P()? here using info from model, so not P(t), more like P(t | model)
    return n_t / n_t.sum()


def compute_joint_pwt_distribution(phi, p_t):
    &#34;&#34;&#34;
    p(t) is prob(topic = t), defined as p(t) = sum_t n_t / n  

    if we fix some word w, we can calculate weighted_pk:  
    wp_t = p(t) p(w|t)

    Parameters
    ----------
    phi : pd.Dataframe
        phi matrix of the model
    p_t : np.array of float
        probability that a random token from the collection belongs to that topic

    Returns
    -------
    joint_pwt : np.array of float
        array of probabilities that a fixed token from the collection
        belongs to that topic

    &#34;&#34;&#34;  # noqa: W291

    joint_pwt = p_t[:, np.newaxis] * phi.transpose()
    return joint_pwt


def compute_ptw(joint_pwt):
    return joint_pwt / np.sum(joint_pwt, axis=0)  # sum by all T


def compute_likelihood_vectorised(phi, p_t, joint_pwt):
    &#34;&#34;&#34;
    Likelihood ratio is defined as  
        L = phi_wt / sum_k p(k)/p(!t) phi_wk  
    equivalently:  
        L = phi_wt * p(!t) / sum_k!=t p(k) phi_wk  
    after some numpy magic, you can get:  
        L = phi[topic, id] * (1 - p_t[topic]) / {(sum(joined_pwt) - joined_pwt[topic])}  
    numerator and denominator are calculated separately.  

    Parameters
    ----------
    phi : pd.Dataframe
        phi matrix of the model
    p_t : np.array of float
        probability that a random token from the collection belongs to that topic
    joint_pwt : np.array of float
        array of probabilities that a fixed token from the collection
        belongs to that topic

    Returns
    -------
    target_values : np.array of float
        vector of likelihood ratios that tokens belong to the given topic

    &#34;&#34;&#34;  # noqa: W291
    # if phi and joint_pwt are DataFrame, then
    # denominator will have the same Index/Columns as them
    # TODO: check equality
    denominator = (np.sum(joint_pwt, axis=0) - joint_pwt)
    multiplier = (1 - p_t)[:, np.newaxis]
    if hasattr(phi, &#34;values&#34;):
        numerator = phi.values.transpose() * multiplier
    else:
        numerator = phi.transpose() * multiplier

    bad_indices = (denominator == 0)
    denominator[bad_indices] = 1
    target_values = numerator / denominator

    # infinite likelihood ratios aren&#39;t interesting
    target_values[bad_indices] = float(&#34;-inf&#34;)
    return target_values


def compute_blei_scores(phi):
    &#34;&#34;&#34;
    Computes Blei score  
    phi[wt] * [log(phi[wt]) - 1/T sum_k log(phi[wk])]

    Parameters
    ----------
    phi : pd.DataFrame
        phi matrix of the model

    Returns
    -------
    score : pd.DataFrame
        weighted phi matrix

    &#34;&#34;&#34;  # noqa: W291

    topic_number = phi.shape[0]
    blei_eps = 1e-42
    log_phi = np.log(phi + blei_eps)
    denominator = np.sum(log_phi, axis=0)
    denominator = denominator[np.newaxis, :]

    if hasattr(log_phi, &#34;values&#34;):
        multiplier = log_phi.values - denominator / topic_number
    else:
        multiplier = log_phi - denominator / topic_number

    score = (phi * multiplier).transpose()
    return score


def compute_clusters_top_tokens_by_clusters_tfidf(
        objects_cluster, objects_content,
        max_top_number=10, n_topics=None):
    &#34;&#34;&#34;
    Function for document-like clusters.  
    For each cluster compute top tokens of cluster. Top tokens are defined by tf-idf scheme.
    Tf-idf is computed as if clusters is concatenation of all it documents.

    Parameters
    ----------
    objects_cluster : list of int
        ith element of list is cluster of ith object
    objects_content : list of list of str
        each element is sequence of tokens
    max_top_number : int
        maximum number of top tokens of cluster (resulting number can be less than it) 
        (Default value = 10)
    n_topics : int
        number of topics in model (Default value = None) 
        if None than it will be calculated automatically from object_clusters

    Returns
    -------
    clusters_top_tokens : list of list of str:
        ith element of list is list of top tokens of ith cluster

    &#34;&#34;&#34;  # noqa: W291
    # TODO: check type of cluster_content, raise Error if it has spaces in it

    n_topics = (
        n_topics if n_topics is not None
        else max(objects_cluster) + 1
    )

    cluster_tokens = {
        num_cluster: []
        for num_cluster in range(n_topics)
    }

    for object_cluster, object_content in zip(objects_cluster, objects_content):
        cluster_tokens[object_cluster] += object_content

    cluster_tokens = [
        cluster_content
        for cluster_label, cluster_content in sorted(cluster_tokens.items(), key=lambda x: x[0])
    ]

    vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)
    tfidf_array = vectorizer.fit_transform(cluster_tokens).toarray()
    index_to_word = [
        word
        for word, index in sorted(vectorizer.vocabulary_.items(), key=lambda x:x[1])
    ]

    cluster_top_tokens_indexes = (
        tfidf_array
        .argsort(axis=1)[:, tfidf_array.shape[1] - max_top_number:]
    )

    cluster_top_tokens = []
    for cluster_label, cluster_top_tokens_indexes in enumerate(cluster_top_tokens_indexes):
        cluster_top_tokens += [
            (index_to_word[index], tfidf_array[cluster_label, index])
            for index in cluster_top_tokens_indexes[::-1]
            if tfidf_array[cluster_label, index] != 0
        ]

    return cluster_top_tokens


# TODO: check why this better than plain df.to_html()
def convert_df_to_html(df):
    return df.style\
               .set_table_attributes(&#34;style=&#39;display:inline&#39;&#34;)\
               ._repr_html_()


class TopTokensViewer(BaseViewer):
    &#34;&#34;&#34;Gets top tokens from topic (sorted by scores)&#34;&#34;&#34;
    def __init__(self,
                 model,
                 class_ids=None,
                 method=&#39;blei&#39;,
                 num_top_tokens=10,
                 alpha=1,
                 dataset=None):
        &#34;&#34;&#34;
        The class provide information about top tokens 
        of the model topics providing with different methods to score that.

        Parameters
        ----------
        model : TopicModel
            a class of topic model
        class_ids : list of int
            class ids for documents in topic needed only for tfidf method
        method : str
            method to score the topics could be any of
            top, phi - top tokens by probability in topic  
            blei - some magical Blei article score  
            tfidf - Term Frequency inversed Document Frequency  
            likelihood - Likelihood ratio score  
            ptw - something like likelihood  
        num_top_tokens : int
            number of top tokens to provide for each topic
        alpha : float between 0 and 1
            additional constant needed for
            ptw method of scoring
        dataset: Dataset
            a class that stores infromation about the collection

        &#34;&#34;&#34;  # noqa: W291
        known = [&#39;top&#39;, &#39;phi&#39;, &#39;blei&#39;, &#39;tfidf&#39;, &#39;likelihood&#39;, &#39;ptw&#39;]

        super().__init__(model=model)

        self.num_top_tokens = num_top_tokens
        self.class_ids = class_ids

        if method in known:
            self.method = method
        else:
            raise ValueError(f&#39;method {method} is not known&#39;)

        self.alpha = alpha
        self._dataset = dataset
        self._cached_top_tokens = None

    @property
    def cached_top_tokens(self):
        if self._cached_top_tokens is None:
            self._cached_top_tokens = self.view(three_levels=False)
        return self._cached_top_tokens

    def _get_target_values(self, phi):
        &#34;&#34;&#34;
        Precomputes various model scores
        &#34;&#34;&#34;
        if self.method == &#39;blei&#39;:
            return compute_blei_scores(phi)

        elif self.method in [&#39;top&#39;, &#39;phi&#39;]:
            return phi.transpose()

        elif self.method in [&#39;ptw&#39;, &#39;likelihood&#39;]:
            p_t = compute_pt_distribution(self._model)
            joint_pwt = compute_joint_pwt_distribution(phi, p_t)

            if self.method == &#39;likelihood&#39;:
                return compute_likelihood_vectorised(phi, p_t, joint_pwt)

            elif self.method == &#39;ptw&#39;:
                ptw_vector = compute_ptw(joint_pwt)
                ptw_component = self.alpha * ptw_vector
                phi_component = (1 - self.alpha) * phi.transpose()

                return ptw_component + phi_component

    def view(
            self,
            class_ids: List[str] = None,
            raw_data: List[List[str]] = None,
            three_levels: bool = True
    ) -&gt; Union[Dict[str, Dict[str, Dict[str, float]]],
               Dict[str, Dict[Tuple[str, str], float]]]:
        &#34;&#34;&#34;
        Returns list of tuples (token, score) for each topic in the model.

        Parameters
        ----------
        class_ids
            Modalities from which to retrieve top tokens
        raw_data : list of list of str
            Necessary for &#39;tfidf&#39; option
        three_levels
            If true, three level dict will be returned, otherwise — two level one
        returns
        -------
        topic_top_tokens : nested 3 or 2-level dict
            Topic -&gt; Modality -&gt; Token -&gt; Probability or
            Topic -&gt; (Modality, Token) -&gt; Probability

        &#34;&#34;&#34;
        if class_ids is None:
            class_ids = self.class_ids

        phi = self.model.get_phi(class_ids=class_ids)

        if self.method == &#39;tfidf&#39;:
            objects_cluster = (
                self._model
                .get_theta(dataset=self._dataset)
                .values
                .argmax(axis=0)
            )
            top_tokens_sorted = compute_clusters_top_tokens_by_clusters_tfidf(
                objects_cluster, raw_data
            )

            return top_tokens_sorted

        target_values = self._get_target_values(phi)

        phi = target_values.T
        phi.index = pd.MultiIndex.from_tuples(phi.index)
        topic_names = phi.columns.values

        if self.class_ids is None:
            modalities = phi.index.levels[0].values
        else:
            modalities = self.class_ids

        topic_top_tokens = {}

        for topic_name in topic_names:
            topic_column = phi[topic_name]
            modality_top_tokens = {}

            for modality in modalities:
                top_tokens_values, top_tokens_indexes = get_top_values(
                    topic_column.loc[modality].values,
                    top_number=self.num_top_tokens,
                )
                top_tokens = topic_column.loc[modality].index[top_tokens_indexes]

                if three_levels:
                    modality_top_tokens[modality] = dict(zip(top_tokens, top_tokens_values))
                else:
                    modality_top_tokens.update(
                        dict(zip([(modality, token) for token in top_tokens], top_tokens_values))
                    )

            topic_top_tokens[topic_name] = modality_top_tokens

        return topic_top_tokens

    def to_html(
            self,
            topic_names: Union[str, List[str]] = None,
            digits: int = 5,
            thresh: float = None,  # Deprecated
            horizontally_stack: bool = True) -&gt; str:
        &#34;&#34;&#34;
        Generates html version of dataframes to be displayed by Jupyter notebooks

        Parameters
        ----------
        topic_names : list of strings
            Initial dictionary keys
        digits : int
            Number of digits to round each probability to
        thresh : float [Deprecated]
            Threshold used for calculating `digits` and throwing out too low probabilities
        horizontally_stack : bool
            if True, then tokens for each modality will be stacked horizontally
            (instead of being a single long multi-line DataFrame)

        Examples
        --------
        &gt;&gt;&gt; from IPython.display import HTML, display_html
        &gt;&gt;&gt;
        &gt;&gt;&gt; # model training here
        &gt;&gt;&gt; # ...
        &gt;&gt;&gt; viewer = TopTokensViewer(model)
        &gt;&gt;&gt; display_html(viewer.to_html(), raw=True)
        &gt;&gt;&gt; # or
        &gt;&gt;&gt; HTML(viewer.to_html())
        &#34;&#34;&#34;
        if topic_names is not None:
            if isinstance(topic_names, str):
                topic_names = [topic_names]
            num_topics_requested = len(topic_names)
            topic_names = [t for t in topic_names if t in self._model.topic_names]
            if len(topic_names) &lt; num_topics_requested:
                warnings.warn(
                    &#39;Some of the requested topics are absent from the model&#39;,
                )

        if thresh is not None:  # TODO: remove thresh some day
            warnings.warn(
                &#39;Don\&#39;t specify `thresh` in `to_html()` anymore, use `digits`&#39;,
                DeprecationWarning
            )

            digits = int(-np.log10(thresh))

        df = self.to_df(topic_names, digits)

        if len(df) &gt; 0:
            for level, old_names in enumerate(df.index.levels):
                new_names = old_names.str.replace(&#39;&lt;&#39;, &#39;&amp;lt;&#39;).str.replace(&#39;&gt;&#39;, &#39;&amp;gt;&#39;)
                renamer = dict(zip(old_names, new_names))
                df.rename(index=renamer, inplace=True, level=level)

        if horizontally_stack:
            modalities = df.index.levels[0].unique()
            result = &#39;&#39;.join(
                convert_df_to_html(df.query(&#34;modality == @m&#34;))
                for m in modalities
            )
            return result

        return convert_df_to_html(df)

    def to_df(self, topic_names: Iterator[str] = None, digits: int = 5) -&gt; pd.DataFrame:
        topic_top_tokens = self.cached_top_tokens

        if topic_names is not None:
            topic_top_tokens = {
                topic: tokens for topic, tokens in topic_top_tokens.items()
                if topic in topic_names
            }
        if not isinstance(digits, int):
            warnings.warn(
                f&#39;Need &#34;int&#34; digits. &#39;
                f&#39;Casting given value &#34;{digits}&#34; of type &#34;{type(digits)}&#34; to int&#39;
            )

            digits = int(digits)

        return self._to_df(topic_top_tokens, digits)

    @staticmethod
    def _to_df(
            topic_top_tokens: Dict[str, Dict[Tuple[str, str], float]],
            digits: int) -&gt; pd.DataFrame:
        df = pd.DataFrame.from_dict(topic_top_tokens).round(digits)
        df.index = pd.MultiIndex.from_tuples(
            df.index,
            names=[&#39;modality&#39;, &#39;token&#39;]  # TODO: names should be the same as in TopicModel&#39;s Phi?
        )

        df.fillna(0.0, inplace=True)

        # Due to some problems with pandas following crunch is applied:
        if len(df.columns) == 1:
            col_to_sort_by = df.columns.values[0]
            return (df.set_index(col_to_sort_by, append=True)
                    .sort_index(level=[0, 2], ascending=[True, False])
                    .reset_index(col_to_sort_by))

        return df

    def view_from_jupyter(
            self,
            topic_names: Union[str, List[str]] = None,
            digits: int = 5,
            horizontally_stack: bool = True,
            display_output: bool = True,
            give_html: bool = False,
    ):
        &#34;&#34;&#34;
        TopTokensViewer method recommended for use
        from jupyter notebooks

        Parameters
        ----------
        topic_names
            topics requested for viewing
        digits
            Number of digits to round each probability to
        horizontally_stack
            if True, then tokens for each modality will be stacked horizontally
            (instead of being a single long multi-line DataFrame)
        display_output
            request for function to output the information
            together with iterable output intended to be used
            as user defined output
        give_html
            return html string generated by the method

        Returns
        -------
        topic_html_strings: list of strings in HTML format

        Examples
        --------
        &gt;&gt;&gt; # model training here
        &gt;&gt;&gt; # ...
        &gt;&gt;&gt; viewer = TopTokensViewer(model)
        &gt;&gt;&gt; information = viewer.view_from_jupyter()
        &gt;&gt;&gt; # or
        &gt;&gt;&gt; information = viewer.view_from_jupyter(output=False)
        &#34;&#34;&#34;
        from IPython.core.display import display_html
        from topicnet.cooking_machine.pretty_output import make_notebook_pretty

        make_notebook_pretty()
        if isinstance(topic_names, list):
            pass
        elif isinstance(topic_names, str):
            topic_names = [topic_names]
        elif topic_names is None:
            topic_names = self._model.topic_names
        else:
            raise TypeError(f&#39;Invalid type `topic_names` type: &#34;{type(topic_names)}&#34;&#39;)

        topic_html_strings = []

        for topic in topic_names:
            topic_html = self.to_html(
                topic_names=topic,
                digits=digits,
                horizontally_stack=horizontally_stack,
            )

            if display_output:
                display_html(topic_html, raw=True)

            topic_html_strings.append(topic_html)
        if give_html:
            return topic_html_strings</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="topicnet.viewers.top_tokens_viewer.compute_blei_scores"><code class="name flex">
<span>def <span class="ident">compute_blei_scores</span></span>(<span>phi)</span>
</code></dt>
<dd>
<section class="desc"><p>Computes Blei score<br>
phi[wt] * [log(phi[wt]) - 1/T sum_k log(phi[wk])]</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>phi</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>phi matrix of the model</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>score</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>weighted phi matrix</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_blei_scores(phi):
    &#34;&#34;&#34;
    Computes Blei score  
    phi[wt] * [log(phi[wt]) - 1/T sum_k log(phi[wk])]

    Parameters
    ----------
    phi : pd.DataFrame
        phi matrix of the model

    Returns
    -------
    score : pd.DataFrame
        weighted phi matrix

    &#34;&#34;&#34;  # noqa: W291

    topic_number = phi.shape[0]
    blei_eps = 1e-42
    log_phi = np.log(phi + blei_eps)
    denominator = np.sum(log_phi, axis=0)
    denominator = denominator[np.newaxis, :]

    if hasattr(log_phi, &#34;values&#34;):
        multiplier = log_phi.values - denominator / topic_number
    else:
        multiplier = log_phi - denominator / topic_number

    score = (phi * multiplier).transpose()
    return score</code></pre>
</details>
</dd>
<dt id="topicnet.viewers.top_tokens_viewer.compute_clusters_top_tokens_by_clusters_tfidf"><code class="name flex">
<span>def <span class="ident">compute_clusters_top_tokens_by_clusters_tfidf</span></span>(<span>objects_cluster, objects_content, max_top_number=10, n_topics=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Function for document-like clusters.<br>
For each cluster compute top tokens of cluster. Top tokens are defined by tf-idf scheme.
Tf-idf is computed as if clusters is concatenation of all it documents.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>objects_cluster</code></strong> :&ensp;<code>list</code> of <code>int</code></dt>
<dd>ith element of list is cluster of ith object</dd>
<dt><strong><code>objects_content</code></strong> :&ensp;<code>list</code> of <code>list</code> of <code>str</code></dt>
<dd>each element is sequence of tokens</dd>
<dt><strong><code>max_top_number</code></strong> :&ensp;<code>int</code></dt>
<dd>maximum number of top tokens of cluster (resulting number can be less than it)
(Default value = 10)</dd>
<dt><strong><code>n_topics</code></strong> :&ensp;<code>int</code></dt>
<dd>number of topics in model (Default value = None)
if None than it will be calculated automatically from object_clusters</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>clusters_top_tokens</code></strong> :&ensp;<code>list</code> of <code>list</code> of <code>str</code>:</dt>
<dd>ith element of list is list of top tokens of ith cluster</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_clusters_top_tokens_by_clusters_tfidf(
        objects_cluster, objects_content,
        max_top_number=10, n_topics=None):
    &#34;&#34;&#34;
    Function for document-like clusters.  
    For each cluster compute top tokens of cluster. Top tokens are defined by tf-idf scheme.
    Tf-idf is computed as if clusters is concatenation of all it documents.

    Parameters
    ----------
    objects_cluster : list of int
        ith element of list is cluster of ith object
    objects_content : list of list of str
        each element is sequence of tokens
    max_top_number : int
        maximum number of top tokens of cluster (resulting number can be less than it) 
        (Default value = 10)
    n_topics : int
        number of topics in model (Default value = None) 
        if None than it will be calculated automatically from object_clusters

    Returns
    -------
    clusters_top_tokens : list of list of str:
        ith element of list is list of top tokens of ith cluster

    &#34;&#34;&#34;  # noqa: W291
    # TODO: check type of cluster_content, raise Error if it has spaces in it

    n_topics = (
        n_topics if n_topics is not None
        else max(objects_cluster) + 1
    )

    cluster_tokens = {
        num_cluster: []
        for num_cluster in range(n_topics)
    }

    for object_cluster, object_content in zip(objects_cluster, objects_content):
        cluster_tokens[object_cluster] += object_content

    cluster_tokens = [
        cluster_content
        for cluster_label, cluster_content in sorted(cluster_tokens.items(), key=lambda x: x[0])
    ]

    vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)
    tfidf_array = vectorizer.fit_transform(cluster_tokens).toarray()
    index_to_word = [
        word
        for word, index in sorted(vectorizer.vocabulary_.items(), key=lambda x:x[1])
    ]

    cluster_top_tokens_indexes = (
        tfidf_array
        .argsort(axis=1)[:, tfidf_array.shape[1] - max_top_number:]
    )

    cluster_top_tokens = []
    for cluster_label, cluster_top_tokens_indexes in enumerate(cluster_top_tokens_indexes):
        cluster_top_tokens += [
            (index_to_word[index], tfidf_array[cluster_label, index])
            for index in cluster_top_tokens_indexes[::-1]
            if tfidf_array[cluster_label, index] != 0
        ]

    return cluster_top_tokens</code></pre>
</details>
</dd>
<dt id="topicnet.viewers.top_tokens_viewer.compute_joint_pwt_distribution"><code class="name flex">
<span>def <span class="ident">compute_joint_pwt_distribution</span></span>(<span>phi, p_t)</span>
</code></dt>
<dd>
<section class="desc"><p>p(t) is prob(topic = t), defined as p(t) = sum_t n_t / n
</p>
<p>if we fix some word w, we can calculate weighted_pk:<br>
wp_t = p(t) p(w|t)</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>phi</code></strong> :&ensp;<code>pd.Dataframe</code></dt>
<dd>phi matrix of the model</dd>
<dt><strong><code>p_t</code></strong> :&ensp;<code>np.array</code> of <code>float</code></dt>
<dd>probability that a random token from the collection belongs to that topic</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>joint_pwt</code></strong> :&ensp;<code>np.array</code> of <code>float</code></dt>
<dd>array of probabilities that a fixed token from the collection
belongs to that topic</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_joint_pwt_distribution(phi, p_t):
    &#34;&#34;&#34;
    p(t) is prob(topic = t), defined as p(t) = sum_t n_t / n  

    if we fix some word w, we can calculate weighted_pk:  
    wp_t = p(t) p(w|t)

    Parameters
    ----------
    phi : pd.Dataframe
        phi matrix of the model
    p_t : np.array of float
        probability that a random token from the collection belongs to that topic

    Returns
    -------
    joint_pwt : np.array of float
        array of probabilities that a fixed token from the collection
        belongs to that topic

    &#34;&#34;&#34;  # noqa: W291

    joint_pwt = p_t[:, np.newaxis] * phi.transpose()
    return joint_pwt</code></pre>
</details>
</dd>
<dt id="topicnet.viewers.top_tokens_viewer.compute_likelihood_vectorised"><code class="name flex">
<span>def <span class="ident">compute_likelihood_vectorised</span></span>(<span>phi, p_t, joint_pwt)</span>
</code></dt>
<dd>
<section class="desc"><p>Likelihood ratio is defined as<br>
L = phi_wt / sum_k p(k)/p(!t) phi_wk<br>
equivalently:<br>
L = phi_wt * p(!t) / sum_k!=t p(k) phi_wk<br>
after some numpy magic, you can get:<br>
L = phi[topic, id] * (1 - p_t[topic]) / {(sum(joined_pwt) - joined_pwt[topic])}<br>
numerator and denominator are calculated separately.
</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>phi</code></strong> :&ensp;<code>pd.Dataframe</code></dt>
<dd>phi matrix of the model</dd>
<dt><strong><code>p_t</code></strong> :&ensp;<code>np.array</code> of <code>float</code></dt>
<dd>probability that a random token from the collection belongs to that topic</dd>
<dt><strong><code>joint_pwt</code></strong> :&ensp;<code>np.array</code> of <code>float</code></dt>
<dd>array of probabilities that a fixed token from the collection
belongs to that topic</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>target_values</code></strong> :&ensp;<code>np.array</code> of <code>float</code></dt>
<dd>vector of likelihood ratios that tokens belong to the given topic</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_likelihood_vectorised(phi, p_t, joint_pwt):
    &#34;&#34;&#34;
    Likelihood ratio is defined as  
        L = phi_wt / sum_k p(k)/p(!t) phi_wk  
    equivalently:  
        L = phi_wt * p(!t) / sum_k!=t p(k) phi_wk  
    after some numpy magic, you can get:  
        L = phi[topic, id] * (1 - p_t[topic]) / {(sum(joined_pwt) - joined_pwt[topic])}  
    numerator and denominator are calculated separately.  

    Parameters
    ----------
    phi : pd.Dataframe
        phi matrix of the model
    p_t : np.array of float
        probability that a random token from the collection belongs to that topic
    joint_pwt : np.array of float
        array of probabilities that a fixed token from the collection
        belongs to that topic

    Returns
    -------
    target_values : np.array of float
        vector of likelihood ratios that tokens belong to the given topic

    &#34;&#34;&#34;  # noqa: W291
    # if phi and joint_pwt are DataFrame, then
    # denominator will have the same Index/Columns as them
    # TODO: check equality
    denominator = (np.sum(joint_pwt, axis=0) - joint_pwt)
    multiplier = (1 - p_t)[:, np.newaxis]
    if hasattr(phi, &#34;values&#34;):
        numerator = phi.values.transpose() * multiplier
    else:
        numerator = phi.transpose() * multiplier

    bad_indices = (denominator == 0)
    denominator[bad_indices] = 1
    target_values = numerator / denominator

    # infinite likelihood ratios aren&#39;t interesting
    target_values[bad_indices] = float(&#34;-inf&#34;)
    return target_values</code></pre>
</details>
</dd>
<dt id="topicnet.viewers.top_tokens_viewer.compute_pt_distribution"><code class="name flex">
<span>def <span class="ident">compute_pt_distribution</span></span>(<span>model, class_ids=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Calculates the Prob(t) vector (vector contains an entry for each topic).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>TopicModel</code></dt>
<dd>model under the scope</dd>
<dt><strong><code>class_ids</code></strong> :&ensp;<code>list</code> of <code>str</code> or <code>None</code></dt>
<dd>list of modalities to consider, which takes all modalities in the model
(Default value = None)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>probability that a random token from the collection belongs to that topic</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_pt_distribution(model, class_ids=None):
    &#34;&#34;&#34;
    Calculates the Prob(t) vector (vector contains an entry for each topic).

    Parameters
    ----------
    model : TopicModel
        model under the scope
    class_ids : list of str or None
        list of modalities to consider, which takes all modalities in the model
        (Default value = None)

    Returns
    -------
    float
        probability that a random token from the collection belongs to that topic

    &#34;&#34;&#34;

    n_wt = model.get_phi(class_ids=class_ids, model_name=model.model_nwt)
    n_t = n_wt.sum(axis=0)  # sum over all words
    # TODO: maybe this is not P(t)
    #  P(t) means prior P()? here using info from model, so not P(t), more like P(t | model)
    return n_t / n_t.sum()</code></pre>
</details>
</dd>
<dt id="topicnet.viewers.top_tokens_viewer.compute_ptw"><code class="name flex">
<span>def <span class="ident">compute_ptw</span></span>(<span>joint_pwt)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_ptw(joint_pwt):
    return joint_pwt / np.sum(joint_pwt, axis=0)  # sum by all T</code></pre>
</details>
</dd>
<dt id="topicnet.viewers.top_tokens_viewer.convert_df_to_html"><code class="name flex">
<span>def <span class="ident">convert_df_to_html</span></span>(<span>df)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_df_to_html(df):
    return df.style\
               .set_table_attributes(&#34;style=&#39;display:inline&#39;&#34;)\
               ._repr_html_()</code></pre>
</details>
</dd>
<dt id="topicnet.viewers.top_tokens_viewer.get_top_values"><code class="name flex">
<span>def <span class="ident">get_top_values</span></span>(<span>values, top_number, return_indexes=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns top_number top values from the matrix for each column.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>values</code></strong> :&ensp;<code>np.array</code></dt>
<dd>a two dimensional array of values</dd>
<dt><strong><code>top_number</code></strong> :&ensp;<code>int</code></dt>
<dd>number of top values to return</dd>
<dt><strong><code>return_indexes</code></strong> :&ensp;<code>bool</code></dt>
<dd>a flag to return indexes together with the top values</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>top_values</code></strong> :&ensp;<code>nd.array</code></dt>
<dd>array of top_number top values for each column of the initial array</dd>
</dl>
<p>(optional) top_indexes : nd.array
array of original indexes for top_values array (Default value = True)</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_top_values(values, top_number, return_indexes=True):
    &#34;&#34;&#34;
    Returns top_number top values from the matrix for each column.

    Parameters
    ----------
    values : np.array
        a two dimensional array of values
    top_number : int
        number of top values to return
    return_indexes : bool
        a flag to return indexes together with the top values

    Returns
    -------
    top_values : nd.array
        array of top_number top values for each column of the initial array
    (optional) top_indexes : nd.array
        array of original indexes for top_values array (Default value = True)

    &#34;&#34;&#34;
    if top_number &gt; len(values):
        top_number = len(values)
        warnings.warn(&#39;num_top_tokens greater than modality size&#39;, UserWarning)

    top_indexes = np.argpartition(
        values, len(values) - top_number
    )[-top_number:]

    top_values = values[top_indexes]
    sorted_top_values_indexes = top_values.argsort()[::-1]

    top_values = top_values[sorted_top_values_indexes]

    # get initial indexes
    top_indexes = top_indexes[sorted_top_values_indexes]

    if return_indexes:
        return top_values, top_indexes

    return top_values</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="topicnet.viewers.top_tokens_viewer.TopTokensViewer"><code class="flex name class">
<span>class <span class="ident">TopTokensViewer</span></span>
<span>(</span><span>model, class_ids=None, method='blei', num_top_tokens=10, alpha=1, dataset=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Gets top tokens from topic (sorted by scores)</p>
<p>The class provide information about top tokens
of the model topics providing with different methods to score that.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>TopicModel</code></dt>
<dd>a class of topic model</dd>
<dt><strong><code>class_ids</code></strong> :&ensp;<code>list</code> of <code>int</code></dt>
<dd>class ids for documents in topic needed only for tfidf method</dd>
<dt><strong><code>method</code></strong> :&ensp;<code>str</code></dt>
<dd>method to score the topics could be any of
top, phi - top tokens by probability in topic<br>
blei - some magical Blei article score<br>
tfidf - Term Frequency inversed Document Frequency<br>
likelihood - Likelihood ratio score<br>
ptw - something like likelihood</dd>
<dt><strong><code>num_top_tokens</code></strong> :&ensp;<code>int</code></dt>
<dd>number of top tokens to provide for each topic</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code> <code>between</code> <code>0</code> <code>and</code> <code>1</code></dt>
<dd>additional constant needed for
ptw method of scoring</dd>
<dt><strong><code>dataset</code></strong> :&ensp;<code>Dataset</code></dt>
<dd>a class that stores infromation about the collection</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TopTokensViewer(BaseViewer):
    &#34;&#34;&#34;Gets top tokens from topic (sorted by scores)&#34;&#34;&#34;
    def __init__(self,
                 model,
                 class_ids=None,
                 method=&#39;blei&#39;,
                 num_top_tokens=10,
                 alpha=1,
                 dataset=None):
        &#34;&#34;&#34;
        The class provide information about top tokens 
        of the model topics providing with different methods to score that.

        Parameters
        ----------
        model : TopicModel
            a class of topic model
        class_ids : list of int
            class ids for documents in topic needed only for tfidf method
        method : str
            method to score the topics could be any of
            top, phi - top tokens by probability in topic  
            blei - some magical Blei article score  
            tfidf - Term Frequency inversed Document Frequency  
            likelihood - Likelihood ratio score  
            ptw - something like likelihood  
        num_top_tokens : int
            number of top tokens to provide for each topic
        alpha : float between 0 and 1
            additional constant needed for
            ptw method of scoring
        dataset: Dataset
            a class that stores infromation about the collection

        &#34;&#34;&#34;  # noqa: W291
        known = [&#39;top&#39;, &#39;phi&#39;, &#39;blei&#39;, &#39;tfidf&#39;, &#39;likelihood&#39;, &#39;ptw&#39;]

        super().__init__(model=model)

        self.num_top_tokens = num_top_tokens
        self.class_ids = class_ids

        if method in known:
            self.method = method
        else:
            raise ValueError(f&#39;method {method} is not known&#39;)

        self.alpha = alpha
        self._dataset = dataset
        self._cached_top_tokens = None

    @property
    def cached_top_tokens(self):
        if self._cached_top_tokens is None:
            self._cached_top_tokens = self.view(three_levels=False)
        return self._cached_top_tokens

    def _get_target_values(self, phi):
        &#34;&#34;&#34;
        Precomputes various model scores
        &#34;&#34;&#34;
        if self.method == &#39;blei&#39;:
            return compute_blei_scores(phi)

        elif self.method in [&#39;top&#39;, &#39;phi&#39;]:
            return phi.transpose()

        elif self.method in [&#39;ptw&#39;, &#39;likelihood&#39;]:
            p_t = compute_pt_distribution(self._model)
            joint_pwt = compute_joint_pwt_distribution(phi, p_t)

            if self.method == &#39;likelihood&#39;:
                return compute_likelihood_vectorised(phi, p_t, joint_pwt)

            elif self.method == &#39;ptw&#39;:
                ptw_vector = compute_ptw(joint_pwt)
                ptw_component = self.alpha * ptw_vector
                phi_component = (1 - self.alpha) * phi.transpose()

                return ptw_component + phi_component

    def view(
            self,
            class_ids: List[str] = None,
            raw_data: List[List[str]] = None,
            three_levels: bool = True
    ) -&gt; Union[Dict[str, Dict[str, Dict[str, float]]],
               Dict[str, Dict[Tuple[str, str], float]]]:
        &#34;&#34;&#34;
        Returns list of tuples (token, score) for each topic in the model.

        Parameters
        ----------
        class_ids
            Modalities from which to retrieve top tokens
        raw_data : list of list of str
            Necessary for &#39;tfidf&#39; option
        three_levels
            If true, three level dict will be returned, otherwise — two level one
        returns
        -------
        topic_top_tokens : nested 3 or 2-level dict
            Topic -&gt; Modality -&gt; Token -&gt; Probability or
            Topic -&gt; (Modality, Token) -&gt; Probability

        &#34;&#34;&#34;
        if class_ids is None:
            class_ids = self.class_ids

        phi = self.model.get_phi(class_ids=class_ids)

        if self.method == &#39;tfidf&#39;:
            objects_cluster = (
                self._model
                .get_theta(dataset=self._dataset)
                .values
                .argmax(axis=0)
            )
            top_tokens_sorted = compute_clusters_top_tokens_by_clusters_tfidf(
                objects_cluster, raw_data
            )

            return top_tokens_sorted

        target_values = self._get_target_values(phi)

        phi = target_values.T
        phi.index = pd.MultiIndex.from_tuples(phi.index)
        topic_names = phi.columns.values

        if self.class_ids is None:
            modalities = phi.index.levels[0].values
        else:
            modalities = self.class_ids

        topic_top_tokens = {}

        for topic_name in topic_names:
            topic_column = phi[topic_name]
            modality_top_tokens = {}

            for modality in modalities:
                top_tokens_values, top_tokens_indexes = get_top_values(
                    topic_column.loc[modality].values,
                    top_number=self.num_top_tokens,
                )
                top_tokens = topic_column.loc[modality].index[top_tokens_indexes]

                if three_levels:
                    modality_top_tokens[modality] = dict(zip(top_tokens, top_tokens_values))
                else:
                    modality_top_tokens.update(
                        dict(zip([(modality, token) for token in top_tokens], top_tokens_values))
                    )

            topic_top_tokens[topic_name] = modality_top_tokens

        return topic_top_tokens

    def to_html(
            self,
            topic_names: Union[str, List[str]] = None,
            digits: int = 5,
            thresh: float = None,  # Deprecated
            horizontally_stack: bool = True) -&gt; str:
        &#34;&#34;&#34;
        Generates html version of dataframes to be displayed by Jupyter notebooks

        Parameters
        ----------
        topic_names : list of strings
            Initial dictionary keys
        digits : int
            Number of digits to round each probability to
        thresh : float [Deprecated]
            Threshold used for calculating `digits` and throwing out too low probabilities
        horizontally_stack : bool
            if True, then tokens for each modality will be stacked horizontally
            (instead of being a single long multi-line DataFrame)

        Examples
        --------
        &gt;&gt;&gt; from IPython.display import HTML, display_html
        &gt;&gt;&gt;
        &gt;&gt;&gt; # model training here
        &gt;&gt;&gt; # ...
        &gt;&gt;&gt; viewer = TopTokensViewer(model)
        &gt;&gt;&gt; display_html(viewer.to_html(), raw=True)
        &gt;&gt;&gt; # or
        &gt;&gt;&gt; HTML(viewer.to_html())
        &#34;&#34;&#34;
        if topic_names is not None:
            if isinstance(topic_names, str):
                topic_names = [topic_names]
            num_topics_requested = len(topic_names)
            topic_names = [t for t in topic_names if t in self._model.topic_names]
            if len(topic_names) &lt; num_topics_requested:
                warnings.warn(
                    &#39;Some of the requested topics are absent from the model&#39;,
                )

        if thresh is not None:  # TODO: remove thresh some day
            warnings.warn(
                &#39;Don\&#39;t specify `thresh` in `to_html()` anymore, use `digits`&#39;,
                DeprecationWarning
            )

            digits = int(-np.log10(thresh))

        df = self.to_df(topic_names, digits)

        if len(df) &gt; 0:
            for level, old_names in enumerate(df.index.levels):
                new_names = old_names.str.replace(&#39;&lt;&#39;, &#39;&amp;lt;&#39;).str.replace(&#39;&gt;&#39;, &#39;&amp;gt;&#39;)
                renamer = dict(zip(old_names, new_names))
                df.rename(index=renamer, inplace=True, level=level)

        if horizontally_stack:
            modalities = df.index.levels[0].unique()
            result = &#39;&#39;.join(
                convert_df_to_html(df.query(&#34;modality == @m&#34;))
                for m in modalities
            )
            return result

        return convert_df_to_html(df)

    def to_df(self, topic_names: Iterator[str] = None, digits: int = 5) -&gt; pd.DataFrame:
        topic_top_tokens = self.cached_top_tokens

        if topic_names is not None:
            topic_top_tokens = {
                topic: tokens for topic, tokens in topic_top_tokens.items()
                if topic in topic_names
            }
        if not isinstance(digits, int):
            warnings.warn(
                f&#39;Need &#34;int&#34; digits. &#39;
                f&#39;Casting given value &#34;{digits}&#34; of type &#34;{type(digits)}&#34; to int&#39;
            )

            digits = int(digits)

        return self._to_df(topic_top_tokens, digits)

    @staticmethod
    def _to_df(
            topic_top_tokens: Dict[str, Dict[Tuple[str, str], float]],
            digits: int) -&gt; pd.DataFrame:
        df = pd.DataFrame.from_dict(topic_top_tokens).round(digits)
        df.index = pd.MultiIndex.from_tuples(
            df.index,
            names=[&#39;modality&#39;, &#39;token&#39;]  # TODO: names should be the same as in TopicModel&#39;s Phi?
        )

        df.fillna(0.0, inplace=True)

        # Due to some problems with pandas following crunch is applied:
        if len(df.columns) == 1:
            col_to_sort_by = df.columns.values[0]
            return (df.set_index(col_to_sort_by, append=True)
                    .sort_index(level=[0, 2], ascending=[True, False])
                    .reset_index(col_to_sort_by))

        return df

    def view_from_jupyter(
            self,
            topic_names: Union[str, List[str]] = None,
            digits: int = 5,
            horizontally_stack: bool = True,
            display_output: bool = True,
            give_html: bool = False,
    ):
        &#34;&#34;&#34;
        TopTokensViewer method recommended for use
        from jupyter notebooks

        Parameters
        ----------
        topic_names
            topics requested for viewing
        digits
            Number of digits to round each probability to
        horizontally_stack
            if True, then tokens for each modality will be stacked horizontally
            (instead of being a single long multi-line DataFrame)
        display_output
            request for function to output the information
            together with iterable output intended to be used
            as user defined output
        give_html
            return html string generated by the method

        Returns
        -------
        topic_html_strings: list of strings in HTML format

        Examples
        --------
        &gt;&gt;&gt; # model training here
        &gt;&gt;&gt; # ...
        &gt;&gt;&gt; viewer = TopTokensViewer(model)
        &gt;&gt;&gt; information = viewer.view_from_jupyter()
        &gt;&gt;&gt; # or
        &gt;&gt;&gt; information = viewer.view_from_jupyter(output=False)
        &#34;&#34;&#34;
        from IPython.core.display import display_html
        from topicnet.cooking_machine.pretty_output import make_notebook_pretty

        make_notebook_pretty()
        if isinstance(topic_names, list):
            pass
        elif isinstance(topic_names, str):
            topic_names = [topic_names]
        elif topic_names is None:
            topic_names = self._model.topic_names
        else:
            raise TypeError(f&#39;Invalid type `topic_names` type: &#34;{type(topic_names)}&#34;&#39;)

        topic_html_strings = []

        for topic in topic_names:
            topic_html = self.to_html(
                topic_names=topic,
                digits=digits,
                horizontally_stack=horizontally_stack,
            )

            if display_output:
                display_html(topic_html, raw=True)

            topic_html_strings.append(topic_html)
        if give_html:
            return topic_html_strings</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="topicnet.viewers.base_viewer.BaseViewer" href="base_viewer.html#topicnet.viewers.base_viewer.BaseViewer">BaseViewer</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="topicnet.viewers.top_tokens_viewer.TopTokensViewer.cached_top_tokens"><code class="name">var <span class="ident">cached_top_tokens</span></code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def cached_top_tokens(self):
    if self._cached_top_tokens is None:
        self._cached_top_tokens = self.view(three_levels=False)
    return self._cached_top_tokens</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="topicnet.viewers.top_tokens_viewer.TopTokensViewer.to_df"><code class="name flex">
<span>def <span class="ident">to_df</span></span>(<span>self, topic_names=None, digits=5)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_df(self, topic_names: Iterator[str] = None, digits: int = 5) -&gt; pd.DataFrame:
    topic_top_tokens = self.cached_top_tokens

    if topic_names is not None:
        topic_top_tokens = {
            topic: tokens for topic, tokens in topic_top_tokens.items()
            if topic in topic_names
        }
    if not isinstance(digits, int):
        warnings.warn(
            f&#39;Need &#34;int&#34; digits. &#39;
            f&#39;Casting given value &#34;{digits}&#34; of type &#34;{type(digits)}&#34; to int&#39;
        )

        digits = int(digits)

    return self._to_df(topic_top_tokens, digits)</code></pre>
</details>
</dd>
<dt id="topicnet.viewers.top_tokens_viewer.TopTokensViewer.to_html"><code class="name flex">
<span>def <span class="ident">to_html</span></span>(<span>self, topic_names=None, digits=5, thresh=None, horizontally_stack=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates html version of dataframes to be displayed by Jupyter notebooks</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>topic_names</code></strong> :&ensp;<code>list</code> of <code>strings</code></dt>
<dd>Initial dictionary keys</dd>
<dt><strong><code>digits</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of digits to round each probability to</dd>
<dt><strong><code>thresh</code></strong> :&ensp;<code>float</code> [<code>Deprecated</code>]</dt>
<dd>Threshold used for calculating <code>digits</code> and throwing out too low probabilities</dd>
<dt><strong><code>horizontally_stack</code></strong> :&ensp;<code>bool</code></dt>
<dd>if True, then tokens for each modality will be stacked horizontally
(instead of being a single long multi-line DataFrame)</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; from IPython.display import HTML, display_html
&gt;&gt;&gt;
&gt;&gt;&gt; # model training here
&gt;&gt;&gt; # ...
&gt;&gt;&gt; viewer = TopTokensViewer(model)
&gt;&gt;&gt; display_html(viewer.to_html(), raw=True)
&gt;&gt;&gt; # or
&gt;&gt;&gt; HTML(viewer.to_html())
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_html(
        self,
        topic_names: Union[str, List[str]] = None,
        digits: int = 5,
        thresh: float = None,  # Deprecated
        horizontally_stack: bool = True) -&gt; str:
    &#34;&#34;&#34;
    Generates html version of dataframes to be displayed by Jupyter notebooks

    Parameters
    ----------
    topic_names : list of strings
        Initial dictionary keys
    digits : int
        Number of digits to round each probability to
    thresh : float [Deprecated]
        Threshold used for calculating `digits` and throwing out too low probabilities
    horizontally_stack : bool
        if True, then tokens for each modality will be stacked horizontally
        (instead of being a single long multi-line DataFrame)

    Examples
    --------
    &gt;&gt;&gt; from IPython.display import HTML, display_html
    &gt;&gt;&gt;
    &gt;&gt;&gt; # model training here
    &gt;&gt;&gt; # ...
    &gt;&gt;&gt; viewer = TopTokensViewer(model)
    &gt;&gt;&gt; display_html(viewer.to_html(), raw=True)
    &gt;&gt;&gt; # or
    &gt;&gt;&gt; HTML(viewer.to_html())
    &#34;&#34;&#34;
    if topic_names is not None:
        if isinstance(topic_names, str):
            topic_names = [topic_names]
        num_topics_requested = len(topic_names)
        topic_names = [t for t in topic_names if t in self._model.topic_names]
        if len(topic_names) &lt; num_topics_requested:
            warnings.warn(
                &#39;Some of the requested topics are absent from the model&#39;,
            )

    if thresh is not None:  # TODO: remove thresh some day
        warnings.warn(
            &#39;Don\&#39;t specify `thresh` in `to_html()` anymore, use `digits`&#39;,
            DeprecationWarning
        )

        digits = int(-np.log10(thresh))

    df = self.to_df(topic_names, digits)

    if len(df) &gt; 0:
        for level, old_names in enumerate(df.index.levels):
            new_names = old_names.str.replace(&#39;&lt;&#39;, &#39;&amp;lt;&#39;).str.replace(&#39;&gt;&#39;, &#39;&amp;gt;&#39;)
            renamer = dict(zip(old_names, new_names))
            df.rename(index=renamer, inplace=True, level=level)

    if horizontally_stack:
        modalities = df.index.levels[0].unique()
        result = &#39;&#39;.join(
            convert_df_to_html(df.query(&#34;modality == @m&#34;))
            for m in modalities
        )
        return result

    return convert_df_to_html(df)</code></pre>
</details>
</dd>
<dt id="topicnet.viewers.top_tokens_viewer.TopTokensViewer.view"><code class="name flex">
<span>def <span class="ident">view</span></span>(<span>self, class_ids=None, raw_data=None, three_levels=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns list of tuples (token, score) for each topic in the model.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>class_ids</code></strong></dt>
<dd>Modalities from which to retrieve top tokens</dd>
<dt><strong><code>raw_data</code></strong> :&ensp;<code>list</code> of <code>list</code> of <code>str</code></dt>
<dd>Necessary for 'tfidf' option</dd>
<dt><strong><code>three_levels</code></strong></dt>
<dd>If true, three level dict will be returned, otherwise — two level one</dd>
</dl>
<h2 id="returns">returns</h2>
<dl>
<dt><strong><code>topic_top_tokens</code></strong> :&ensp;<code>nested</code> <code>3</code> or <code>2</code>-<code>level</code> <code>dict</code></dt>
<dd>Topic -&gt; Modality -&gt; Token -&gt; Probability or
Topic -&gt; (Modality, Token) -&gt; Probability</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def view(
        self,
        class_ids: List[str] = None,
        raw_data: List[List[str]] = None,
        three_levels: bool = True
) -&gt; Union[Dict[str, Dict[str, Dict[str, float]]],
           Dict[str, Dict[Tuple[str, str], float]]]:
    &#34;&#34;&#34;
    Returns list of tuples (token, score) for each topic in the model.

    Parameters
    ----------
    class_ids
        Modalities from which to retrieve top tokens
    raw_data : list of list of str
        Necessary for &#39;tfidf&#39; option
    three_levels
        If true, three level dict will be returned, otherwise — two level one
    returns
    -------
    topic_top_tokens : nested 3 or 2-level dict
        Topic -&gt; Modality -&gt; Token -&gt; Probability or
        Topic -&gt; (Modality, Token) -&gt; Probability

    &#34;&#34;&#34;
    if class_ids is None:
        class_ids = self.class_ids

    phi = self.model.get_phi(class_ids=class_ids)

    if self.method == &#39;tfidf&#39;:
        objects_cluster = (
            self._model
            .get_theta(dataset=self._dataset)
            .values
            .argmax(axis=0)
        )
        top_tokens_sorted = compute_clusters_top_tokens_by_clusters_tfidf(
            objects_cluster, raw_data
        )

        return top_tokens_sorted

    target_values = self._get_target_values(phi)

    phi = target_values.T
    phi.index = pd.MultiIndex.from_tuples(phi.index)
    topic_names = phi.columns.values

    if self.class_ids is None:
        modalities = phi.index.levels[0].values
    else:
        modalities = self.class_ids

    topic_top_tokens = {}

    for topic_name in topic_names:
        topic_column = phi[topic_name]
        modality_top_tokens = {}

        for modality in modalities:
            top_tokens_values, top_tokens_indexes = get_top_values(
                topic_column.loc[modality].values,
                top_number=self.num_top_tokens,
            )
            top_tokens = topic_column.loc[modality].index[top_tokens_indexes]

            if three_levels:
                modality_top_tokens[modality] = dict(zip(top_tokens, top_tokens_values))
            else:
                modality_top_tokens.update(
                    dict(zip([(modality, token) for token in top_tokens], top_tokens_values))
                )

        topic_top_tokens[topic_name] = modality_top_tokens

    return topic_top_tokens</code></pre>
</details>
</dd>
<dt id="topicnet.viewers.top_tokens_viewer.TopTokensViewer.view_from_jupyter"><code class="name flex">
<span>def <span class="ident">view_from_jupyter</span></span>(<span>self, topic_names=None, digits=5, horizontally_stack=True, display_output=True, give_html=False)</span>
</code></dt>
<dd>
<section class="desc"><p>TopTokensViewer method recommended for use
from jupyter notebooks</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>topic_names</code></strong></dt>
<dd>topics requested for viewing</dd>
<dt><strong><code>digits</code></strong></dt>
<dd>Number of digits to round each probability to</dd>
<dt><strong><code>horizontally_stack</code></strong></dt>
<dd>if True, then tokens for each modality will be stacked horizontally
(instead of being a single long multi-line DataFrame)</dd>
<dt><strong><code>display_output</code></strong></dt>
<dd>request for function to output the information
together with iterable output intended to be used
as user defined output</dd>
<dt><strong><code>give_html</code></strong></dt>
<dd>return html string generated by the method</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>topic_html_strings</code></strong> :&ensp;<code>list</code> of <code>strings</code> <code>in</code> <code>HTML</code> <code>format</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code>&gt;&gt;&gt; # model training here
&gt;&gt;&gt; # ...
&gt;&gt;&gt; viewer = TopTokensViewer(model)
&gt;&gt;&gt; information = viewer.view_from_jupyter()
&gt;&gt;&gt; # or
&gt;&gt;&gt; information = viewer.view_from_jupyter(output=False)
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def view_from_jupyter(
        self,
        topic_names: Union[str, List[str]] = None,
        digits: int = 5,
        horizontally_stack: bool = True,
        display_output: bool = True,
        give_html: bool = False,
):
    &#34;&#34;&#34;
    TopTokensViewer method recommended for use
    from jupyter notebooks

    Parameters
    ----------
    topic_names
        topics requested for viewing
    digits
        Number of digits to round each probability to
    horizontally_stack
        if True, then tokens for each modality will be stacked horizontally
        (instead of being a single long multi-line DataFrame)
    display_output
        request for function to output the information
        together with iterable output intended to be used
        as user defined output
    give_html
        return html string generated by the method

    Returns
    -------
    topic_html_strings: list of strings in HTML format

    Examples
    --------
    &gt;&gt;&gt; # model training here
    &gt;&gt;&gt; # ...
    &gt;&gt;&gt; viewer = TopTokensViewer(model)
    &gt;&gt;&gt; information = viewer.view_from_jupyter()
    &gt;&gt;&gt; # or
    &gt;&gt;&gt; information = viewer.view_from_jupyter(output=False)
    &#34;&#34;&#34;
    from IPython.core.display import display_html
    from topicnet.cooking_machine.pretty_output import make_notebook_pretty

    make_notebook_pretty()
    if isinstance(topic_names, list):
        pass
    elif isinstance(topic_names, str):
        topic_names = [topic_names]
    elif topic_names is None:
        topic_names = self._model.topic_names
    else:
        raise TypeError(f&#39;Invalid type `topic_names` type: &#34;{type(topic_names)}&#34;&#39;)

    topic_html_strings = []

    for topic in topic_names:
        topic_html = self.to_html(
            topic_names=topic,
            digits=digits,
            horizontally_stack=horizontally_stack,
        )

        if display_output:
            display_html(topic_html, raw=True)

        topic_html_strings.append(topic_html)
    if give_html:
        return topic_html_strings</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="topicnet.viewers" href="index.html">topicnet.viewers</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="topicnet.viewers.top_tokens_viewer.compute_blei_scores" href="#topicnet.viewers.top_tokens_viewer.compute_blei_scores">compute_blei_scores</a></code></li>
<li><code><a title="topicnet.viewers.top_tokens_viewer.compute_clusters_top_tokens_by_clusters_tfidf" href="#topicnet.viewers.top_tokens_viewer.compute_clusters_top_tokens_by_clusters_tfidf">compute_clusters_top_tokens_by_clusters_tfidf</a></code></li>
<li><code><a title="topicnet.viewers.top_tokens_viewer.compute_joint_pwt_distribution" href="#topicnet.viewers.top_tokens_viewer.compute_joint_pwt_distribution">compute_joint_pwt_distribution</a></code></li>
<li><code><a title="topicnet.viewers.top_tokens_viewer.compute_likelihood_vectorised" href="#topicnet.viewers.top_tokens_viewer.compute_likelihood_vectorised">compute_likelihood_vectorised</a></code></li>
<li><code><a title="topicnet.viewers.top_tokens_viewer.compute_pt_distribution" href="#topicnet.viewers.top_tokens_viewer.compute_pt_distribution">compute_pt_distribution</a></code></li>
<li><code><a title="topicnet.viewers.top_tokens_viewer.compute_ptw" href="#topicnet.viewers.top_tokens_viewer.compute_ptw">compute_ptw</a></code></li>
<li><code><a title="topicnet.viewers.top_tokens_viewer.convert_df_to_html" href="#topicnet.viewers.top_tokens_viewer.convert_df_to_html">convert_df_to_html</a></code></li>
<li><code><a title="topicnet.viewers.top_tokens_viewer.get_top_values" href="#topicnet.viewers.top_tokens_viewer.get_top_values">get_top_values</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="topicnet.viewers.top_tokens_viewer.TopTokensViewer" href="#topicnet.viewers.top_tokens_viewer.TopTokensViewer">TopTokensViewer</a></code></h4>
<ul class="">
<li><code><a title="topicnet.viewers.top_tokens_viewer.TopTokensViewer.cached_top_tokens" href="#topicnet.viewers.top_tokens_viewer.TopTokensViewer.cached_top_tokens">cached_top_tokens</a></code></li>
<li><code><a title="topicnet.viewers.top_tokens_viewer.TopTokensViewer.to_df" href="#topicnet.viewers.top_tokens_viewer.TopTokensViewer.to_df">to_df</a></code></li>
<li><code><a title="topicnet.viewers.top_tokens_viewer.TopTokensViewer.to_html" href="#topicnet.viewers.top_tokens_viewer.TopTokensViewer.to_html">to_html</a></code></li>
<li><code><a title="topicnet.viewers.top_tokens_viewer.TopTokensViewer.view" href="#topicnet.viewers.top_tokens_viewer.TopTokensViewer.view">view</a></code></li>
<li><code><a title="topicnet.viewers.top_tokens_viewer.TopTokensViewer.view_from_jupyter" href="#topicnet.viewers.top_tokens_viewer.TopTokensViewer.view_from_jupyter">view_from_jupyter</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.2</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>